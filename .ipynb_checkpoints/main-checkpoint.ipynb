{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Film Casus\n",
    "\n",
    "Welkom bij het onderzoek van Team 1! \n",
    "\n",
    "- Gemaakt door Yula, Joel en Pim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "In dit project gaan wij 2 filmdatasets onderzoeken. \n",
    "\n",
    "Voor dat we gaan beginnen gaan we eerste nog **data begrijpen** en **data voorbereiden**.\n",
    "\n",
    "We beantwoorden totaal 3 onderzoeksvragen：\n",
    "1. In hoeverre is de omzet van een film te voorspellen op basis van de populariteit op Facebook en IMDB？\n",
    "2. Is het mogelijk om te voorspellen of een film een oscar zal winnen of niet?\n",
    "3. Hoe kunnen budget en omzet worden gebruikt om logische clusters van de films te vinden?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "**Alle imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functies as fn\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "from sklearn.mixture import GaussianMixture as gmm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Laad de dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = pd.read_csv('data/movie-1.csv')\n",
    "\n",
    "# Toon de maximale informatie die de dataframe kan geven.\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Formatteer alle grote getallen voor een betere leesbaarheid.\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kopie van de dataset**\n",
    "\n",
    "\n",
    "Een kopie van de gegevens maken om mee te werken,\n",
    "zodat we het oorspronkelijke dataset niet wijzigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfr.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Een kijkje nemen naar de gegevens die we hebben gekregen.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Haal de kolomnamen op om te zien met wat voor soort variabelen we werken**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meetniveaus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  alle meetniveaus in datafeame zetten\n",
    "data = {\n",
    "    \"Nominaal\": [\n",
    "        \"actor_1_name\", \"actor_2_name\", \"actor_3_name\", \"color\", \"country\",\n",
    "        \"director_name\", \"genres\", \"language\", \"movie_imdb_link\", \"movie_title\", \"plot_keywords\"\n",
    "    ],\n",
    "    \"Ordinaal\": [\"content_rating\"],\n",
    "    \"Discreet\": [\n",
    "        \"facenumber_in_poster\", \"num_critic_for_reviews\", \"num_user_for_reviews\",\n",
    "        \"num_voted_users\", \"title_year\"\n",
    "    ],\n",
    "    \"Continu\": [\n",
    "        \"actor_1_facebook_likes\", \"actor_2_facebook_likes\", \"actor_3_facebook_likes\",\n",
    "        \"aspect_ratio\", \"budget\", \"cast_total_facebook_likes\", \"director_facebook_likes\",\n",
    "        \"duration\", \"gross\", \"imdb_score\", \"movie_facebook_likes\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "meetniveaus = pd.DataFrame.from_dict(data, orient='index').transpose()\n",
    "\n",
    "print(meetniveaus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Doel- en kenmerkenvariabelen**\n",
    "\n",
    "\n",
    "De target variabel is al gegeven, namelijk de 'gross' kolom.\n",
    "\n",
    "De gross is afhankelijk van de feature variables, die zijn onafhankelijk.\n",
    "\n",
    "We hebben gekozen voor deze feature variabelen omdat deze kolommen het best passen bij onze onderzoeksvraag. \n",
    "\n",
    "We moeten het voorspellen aan de hand van de populariteit van facebook en IMDB. Ofwel de statistieken van deze 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureVariables = ['director_facebook_likes', \n",
    "                    'actor_1_facebook_likes', \n",
    "                    'actor_2_facebook_likes', \n",
    "                    'actor_3_facebook_likes', \n",
    "                    'cast_total_facebook_likes', \n",
    "                    'movie_facebook_likes', \n",
    "                    'imdb_score']\n",
    "\n",
    "targetVariable = ['gross']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Maak een andere dataframe met alleen de kolommen waarin we geïnteresseerd zijn voor vraag 1.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vraag1 = df[featureVariables + targetVariable]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Controleer NaN-waarden**\n",
    "\n",
    "Verwijder voorlopig alle NaN-waarden in de kenmerken- en doelvariabelen. Later zullen we verder onderzoeken hoe we deze op de juiste manier kunnen verwerken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vraag1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zullen alle NaN-waarden verwijderen. We kunnen ze niet vervangen, omdat de meerderheid onze doelvariabele bevat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape) #check impact\n",
    "df_vraag1 = df.dropna()\n",
    "print(df_vraag1.shape) #check impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nu zullen we alle kolommen analyseren om te controleren op anomalieën.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vraag1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle statistieken zien er schoon uit.\n",
    "\n",
    "Alle kolommen met 'namen' bevatten NaN en getallen waar dit verwacht wordt.\n",
    "\n",
    "Alle kolommen met 'likes' bevatten NaN en een getal waar dit verwacht wordt. Ook geen vreemde minimale of maximale waarden.\n",
    "\n",
    "De kolom 'imdb_score' heeft alleen waarden tussen 0 en 10, wat verwacht wordt.\n",
    "\n",
    "En tot slot heeft de kolom 'gross' een natuurlijke orde van grootte van min tot max."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TargetVariable met histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.histogram_gross(df_vraag1,targetVariable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deze histogram laat zien hoe vaak verschillende filmomzetten voorkomen. De meeste films verdienen minder dan $100 miljoen, terwijl slechts een paar films veel meer verdienen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TargetVariable met boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zullen geen van de uitschieters uit onze doelvariabele 'gross' verwijderen. Voor onze kenmerkenvariabelen zijn er echter enkele vreemde uitschieters en veel regisseurs en acteurs met 0 likes op Facebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.boxplot_gross_and_budget(df_vraag1,targetVariable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deze boxplot van gross laat ook zien dat de meeste films een omzet hebben onder $100 miljoen, maar er zijn veel uitschieters met een veel hogere omzet, tot boven $700 miljoen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FeatureVariables met histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.plot_histograms(df_vraag1, featureVariables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**imdb_score**\n",
    "\n",
    "De verdeling van deze featureVariabele is relatief normaal verdeeld, wat betekent dat de meeste films een IMDb-score tussen 5 en 7 hebben.\n",
    "\n",
    "**Andere Variabelen met likes**\n",
    "\n",
    "Veel van deze featureVariabelen hebben een scheve verdeling, waarbij de meeste films weinig likes hebben en een paar films veel likes. Dit kan zijn door heel bekend regisseurs en acteurs in bepaald films."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurevariables met boxplots en uitschieters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Er is super veel variatie tussen alle feature variabelen. Wij verwachten dat films met een hoge like score op alle gebieden, hoger zal scoren in hun omzet. Dus Wij zullen geen uitschieters verwijderen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.plot_boxplots(df_vraag1, featureVariables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**imdb_score**\n",
    "\n",
    "Deze featureVariabel heeft geen duidelijke outliers. Dit maakt het betrouwbaarder en gemakkelijker te gebruiken in onze modellen.\n",
    "\n",
    "**Andere Variabelen met likes**\n",
    "\n",
    "Zoals wij bij histogram hebben gezien, veel van deze featureVariabelen hebben een scheve verdeling, waardoor modellen mogelijk worden beïnvloed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlatie tussen TargetVariable en FeatureVariables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gaan hier met scatterplots onderzoeken wat de relatie is tussen het aantal Facebook-likes van de regisseur, de acteurs, de film, de IMDb-score en de hele cast en de totale opbrengst van de film."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scatterplots**\n",
    "\n",
    "Bereken de feature variabelen tegenover de doelvariabele, zodat we kunnen zien welke kenmerken (enigszins) belangrijk zijn voor de doelvariabele\n",
    "\n",
    "Zoals je kunt aflezen is er geen enkele feature variabele die met zekerheid een positieve correlatie heeft. De hoogste heeft een 0.38 wat maar een matige positieve correlatie weergeeft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = df_vraag1[featureVariables + targetVariable].corr()['gross'].sort_values(ascending=False)\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.pairgrid_plot(df_vraag1, featureVariables, targetVariable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resultaat**\n",
    "\n",
    "Deze plot toont de relatie tussen de targetvariabele gross en de verschillende featurevariabelen. De **blauwe punten** zijn de gegevenspunten en de **rode lijn** is een lineaire regressielijn. Hoe schuiner de lijn, hoe hoger de correlatie tussen beide kenmerken.\n",
    "\n",
    "We zien duidelijk dat een stijgende rode lijn, zoals bij movie_facebook_likes, een positieve relatie heeft. Dit klopt ook, want movie_facebook_likes heeft een positieve correlatie van 0,38.\n",
    "\n",
    "Bij een vlakke lijn, zoals bij director_facebook_likes, is er een zwakke of bijna geen relatie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onderzoeksvraag 1: In hoeverre is de omzet van een film te voorspellen op basis van de populariteit op Facebook en IMDB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modellen ##\n",
    "\n",
    "Hier gaan we de modellen toepassen op onze data. \n",
    "\n",
    "Als eerst gaan we een train test split maken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_vraag1[featureVariables]\n",
    "y = df_vraag1[targetVariable]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "\n",
    "Een baseline score is nodig om te kijken hoe ver onze modellen hiervan afwijken. Als de score van ons complexere model eronder zit doet het model het beter dan de baseline model wat goed is, als de score erboven zit doet het model het slechter en is dit een reden om dat model niet te gaan gebruiken.\n",
    "\n",
    "De baseline bereken je met de 'mean_squared_error' uitgedrukt in RMSE. \n",
    "\n",
    "De baseline score geeft ons een referentie voor onze modelprestaties. Elk model dat op zijn minst beter presteert dan deze baseline is een verbetering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dit gemiddelde word als de \"baseline\" voorspelling gebruikt voor alle tests.\n",
    "baseline = np.mean(y_train)\n",
    "\n",
    "# Dit betekent dat elke voorspelling hetzelfde is en gelijk is aan het gemiddelde van y_train.\n",
    "y_pred = np.ones(len(X_test)) * baseline\n",
    "\n",
    "# 'squared=False' geeft aan dat de wortel van de mean squared errror word genomen, zodat je de RMSE krijgt.\n",
    "baseline_score = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "print(f\"RMSE: {baseline_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linieare Regressie\n",
    "\n",
    "Als eerst gaan we linieare regressie toepassen. \n",
    "\n",
    "De data gaan we ook normaliseren. Normaliseren is nodig om het linieare regressie model beter te laten werken omdat het model werkt op relatieve afstanden van elkaar.\n",
    "\n",
    "Bij dit model hebben we niet gekozen voor hyperparameters, dit model is vrij simpel en geeft alleen een directe oplossing door de normale vergelijking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Een genormaliseerde train en test maken\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maak een lineaire regressie model aan\n",
    "lr = lm.LinearRegression()\n",
    "\n",
    "# Fit het model met de trainings data\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Bereken de voorspellingen voor de test data\n",
    "y_pred = lr.predict(X_test_scaled)\n",
    "\n",
    "# Bereken de RMSE\n",
    "lr_score = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f\"Root Mean Squared Error: {lr_score:.2f}\")\n",
    "\n",
    "# Bereken de R^2 score voor het regressiemodel\n",
    "lr_r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {lr_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De uitkomst van dit model is 58977858.91 en zit met 14,94% onder het baseline model wat goed is.\n",
    "\n",
    "De R-squared is 0.29. Dit model kan ongeveer 29% van de variatie in de variabele kan verklaren. \n",
    "\n",
    "Dit is niet al te best. Dit duid op een niet linieare relatie. (dit hadden we ook gezien bij de correlatie plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN\n",
    "\n",
    "Hier gaan we KNN toepassen. De hyperparameters zijn n_neighbors=15, weights=\"distance\", p=2.\n",
    "\n",
    "We hebben gekozen voor N_neighbors=15 want uit code blijkt beste aantal buren is gelijk aan 15.\n",
    "\n",
    "Ook hebben we gekozen voor p=2. Dit neemt de euclidische afstand, ipv p=1 de minkowski afstand. Dit geeft voor onze dataset het beste resultaat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code uit de les van CM09\n",
    "data = []\n",
    "\n",
    "max_n = 15\n",
    "\n",
    "for i in range(1, max_n + 1):\n",
    "    knn = KNeighborsRegressor(n_neighbors=i, weights=\"distance\", p=2)\n",
    "\n",
    "    # Fitten met trainingsdaata\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Bereken de voorspellingen\n",
    "    y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "    # Bereken de RMSE\n",
    "    knn_score = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "    data.append([i, knn_score])\n",
    "\n",
    "\n",
    "df_knn = pd.DataFrame(data, columns=['n', 'RMSE'])\n",
    "\n",
    "fig = plt.figure(figsize=(6,5), dpi=150)\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.set(xlim=(1,max_n),\n",
    "       xlabel='Aantal buren (n)',\n",
    "       ylabel='RMSE',\n",
    "       title='KNN: score vs n')\n",
    "\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(15))\n",
    "ax.ticklabel_format(useOffset=False)\n",
    "ax.plot(df_knn['n'], df_knn['RMSE'], '-o')\n",
    "\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(fn.euro_formatter))\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beste aantal buren berekenen\n",
    "best_n = None\n",
    "best_rmse = float('inf')\n",
    "\n",
    "for index, row in df_knn.iterrows():\n",
    "    if row['RMSE'] < best_rmse:\n",
    "        best_n = row['n']\n",
    "        best_rmse = row['RMSE']\n",
    "\n",
    "print(f\"Beste n: {int(best_n)} met RMSE = {best_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN regressie model met hyperparameters\n",
    "knn = KNeighborsRegressor(n_neighbors=int(best_n), weights=\"distance\", p=2)\n",
    "\n",
    "# Fitten met trainingsdaata\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Bereken de voorspellingen\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "# Bereken de RMSE\n",
    "knn_score = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f\"Root Mean Squared Error: {knn_score:.2f}\")\n",
    "\n",
    "# Bereken de R^2 score voor het KNN model\n",
    "knn_r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {knn_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De uitkomst van dit model is 58.339.596,58, wat 16,37% onder het baseline model ligt, wat goed is. \n",
    "\n",
    "De R-squared waarde is 0,30, wat aangeeft dat dit model ongeveer 30% van de variatie in de afhankelijke variabele kan verklaren, wat nog steeds niet goed genoeg is. \n",
    "\n",
    "Dit wijst op een niet-lineaire relatie tussen de variabelen (dit was ook te zien in de correlatieplots)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor\n",
    "\n",
    "We passen nu een decision tree regressor toe. Deze keuze hebben we gemaakt omdat deze beter om zou moeten kunnen gaan met niet lineare verbanden. \n",
    "\n",
    "Wat goed uitkomt want uit ons correlatie onderzoek is een slechte correlatie gekomen. \n",
    "\n",
    "We hoeven ook geen gebruik te maken van een scalar om te normaliseren. Een DTR kan hiermee omgaan.\n",
    "\n",
    "We gebruiken max_depth=3 omdat dit het 'beste' model is wat we hebben. Zelfs door veel verder te gaan in de boom wordt de score alleen maar slechter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "max_depth = 15\n",
    "\n",
    "for i in range(1, max_depth + 1):\n",
    "    # DTR met alle max_depths\n",
    "    tree = DecisionTreeRegressor(max_depth=i, random_state=42)\n",
    "    \n",
    "    # Fitten met niet gescalede data\n",
    "    tree.fit(X_train, y_train)\n",
    "    \n",
    "    # Bereken de voorspellingen\n",
    "    y_pred = tree.predict(X_test)\n",
    "    \n",
    "    # Bereken de RMSE\n",
    "    tree_score = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    \n",
    "    data.append([i, tree_score])\n",
    "\n",
    "df_tree = pd.DataFrame(data, columns=['max_depth', 'RMSE'])\n",
    "\n",
    "# Plotten van de resultaten\n",
    "fig = plt.figure(figsize=(5, 5), dpi=150)\n",
    "ax = plt.axes()\n",
    "\n",
    "# Instellen van de plotlimieten en labels\n",
    "ax.set(xlim=(1, max_depth),\n",
    "       xlabel='max_depth',\n",
    "       ylabel='RMSE',\n",
    "       title='Decision Tree: RMSE vs max_depth')\n",
    "\n",
    "ax.plot(df_tree['max_depth'], df_tree['RMSE'], '-o')\n",
    "\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(fn.euro_formatter))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regressor initialiseren en trainen\n",
    "tree_regressor = DecisionTreeRegressor(max_depth=3,random_state=42)\n",
    "tree_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Voorspellingen doen op de test set\n",
    "y_pred = tree_regressor.predict(X_test)\n",
    "\n",
    "# Evaluatie van het model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "tree_score = mse ** 0.5\n",
    "print(f\"Root Mean Squared Error (RMSE): {tree_score:.2f}\")\n",
    "\n",
    "# Bereken de R^2 score voor het Decision Tree model\n",
    "tree_r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {tree_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De uitkomst van dit model is 62424735.88, wat met 10,52% boven het baseline model zit wat goed is. \n",
    "\n",
    "Een R-squared van 0.18 wat aangeeft dat dit model ongeveer 19% van de variatie in de variabele kan verklaren wat slecht is. \n",
    "\n",
    "Dit is niet al te best. Dit duid op een niet linieare relatie. (dit hadden we ook gezien bij de correlatie plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusie onderzoeksvraag 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  samenvatting van alle resultaten uit modellen\n",
    "results = []\n",
    "\n",
    "results.append(['Linear Regression', lr_score, lr_r2])\n",
    "results.append(['KNN Regression', knn_score, knn_r2])\n",
    "results.append(['Decision Tree Regression', tree_score, tree_r2])\n",
    "\n",
    "df_results = pd.DataFrame(results, columns=['Model', 'RMSE', 'R²'])\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Het KNN model** doet het iets beter dan lineaire regressie, maar het verschil is klein. Het KNN model werkt ook beter dan het baseline model en het beslissingsboommodel (DTR). \n",
    "\n",
    "Het KNN model heeft R² = 0.30, wat ook niet goed is en betekent dat het model maar 30% van de verschillen in omzet kan verklaren.\n",
    "\n",
    "**Hiermee concluderen we dat de omzet van een film niet te voorspellen is op basis van de populariteit op facebook en IMDB.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onderzoeksvraag 2: Is het mogelijk om te voorspellen of een film een oscar zal winnen of niet?\n",
    "\n",
    "Een oscar winnen is een hele eer in de filmindustrie. Het is dus zeer interessant of we wellicht een model kunnen bouwen welke film een oscar zou winnen of niet, een simpele ja of nee. We hebben dus te maken met een *binaire classificatieprobleem*.\n",
    "\n",
    "We kiezen hier later 3 modellen voor: Logistic Regression, Decision Tree en KNN. Laten we voor nu de data induiken en zien wat we hebben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inladen db\n",
    "\n",
    "oscar_db = pd.read_csv('data/the_oscar_award.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check of alles correct is ingeladen\n",
    "\n",
    "oscar_db.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien hier 7 tabellen terug de Target waarop wij gaan focussen is de 'Winner' tabel. Daarin kunnen we zien of een film een oscar heeft gewonnen of niet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oscar_db.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieruit volgt dat tabel 'ceremony' gewoonweg bijhoudt hoeveel keer de oscar awards zijn gehouden. en de year_film en year_ceremony gewoonweg in welk jaar het evenement zich plaatsvond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oscar_db.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check hoeveel True en False er zijn in de Winner tabel (oftewel hoeveel films een oscar hebben gewonnen of niet)\n",
    "true_count = oscar_db['winner'].value_counts()[True]\n",
    "false_count = oscar_db['winner'].value_counts()[False]\n",
    "\n",
    "# Benaming voor de taart diagram\n",
    "labels = ['Won Oscar', 'Did Not Win Oscar']\n",
    "\n",
    "# Data om te plotten\n",
    "sizes = [true_count, false_count]\n",
    "\n",
    "# Maak taart diagram\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=320, explode = [0.1,0],colors=['lightblue', 'lightcoral'])\n",
    "plt.title('Oscar Wins Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien dus dat minder dan een vierde van de genomineerde een Oscar wint. Laten we de twee datasets mergen, zo kunnen we niet alleen beter zien welke films werden genomineerd, maar ook welke *niet* zijn genomineerd. Voordat we mergen laten we deze dataset eerst opschonen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missende waardes analyseren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oscar_db.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laten we kijken waarom er 319 films een Nan waarde geven. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_films = oscar_db[oscar_db['film'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_films['winner'].value_counts() # Check hoeveel van die missende waardes een oscar hebben gewonnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_films[['name','category','winner']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het ziet ernaar uit dat het geen foute waardes zijn. Deze oscars waren gelinkt aan prestaties van een bedrijf of een individu, en was dus niet per se gelinkt aan een individuele film. Maar aangezien ze niet gelinkt zijn aan een film titel gaan we deze missende waardes dus verwijderen. Aangezien ze niet helpen met de onderzoeksvraag. Laten we alleen nog even kijken naar de 5 missende 'names'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oscar_db[oscar_db['name'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oscar_db[oscar_db['category'] == 'JEAN HERSHOLT HUMANITARIAN AWARD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het blijkt dat de 'JEAN HERSHOLT HUMANITARIAN AWARD' 5 waardes heeft waarvan er geen naam in is gevuld, dus we weten niet wie deze award heeft gewonnen. En aangezien er maar 5 missende 'names' zijn in de hele dataset is het dus veilig om deze fouten eruit te halen. \n",
    "\n",
    "### Conclusie missende waardes\n",
    "Beide tabellen worden verwijderd uit de dataset. Beide tabellen zeggen niks over het feit dat een film een oscar won of niet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_oscar_db = oscar_db.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_oscar_db.dropna(subset='film', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean_oscar_db.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers analyseren\n",
    "\n",
    "Nu dat we geen foutieve lege waardes hebben, laten we kijken of er bepaalde uitschieters zijn in onze data. Aangezien we met nominale waardes werken is het beter om puur te kijken welke waardes 'zeldzaam' zijn. Oftewel zeer weinig voorkomen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_counts = clean_oscar_db['category'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maak een horizontale barplot\n",
    "plt.figure(figsize=(10, 25))\n",
    "sns.barplot(x=cat_counts.values, y=cat_counts.index)\n",
    "plt.xlabel('Aantal nominaties')\n",
    "plt.ylabel('Categorieën')\n",
    "plt.title('Frequentie van Oscar-categorieën')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorieën samenvoegen\n",
    "We zien een rechtscheve verdeling van de data. Het gemiddelde ligt veel hoger dan de mediaan en de standaarddeviatie is ook zeer hoog. \n",
    "\n",
    "Het lijkt mij een goed idee om categorieën bij elkaar te groeperen die heel erg op elkaar lijken om zo minder unieke waardes te hebben, wat makkelijker voor ons model is om over te voorspellen. \n",
    "\n",
    "Ook gaan we overige waardes plaatsen in een nieuwe categorie genaamd 'Other'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samenvoegen van vergelijkbare categorieën\n",
    "clean_oscar_db['category'] = clean_oscar_db['category'].replace({\n",
    "    r'^MUSIC.*': 'MUSIC',\n",
    "    r'^WRITING.*': 'WRITING',\n",
    "    r'^SHORT SUBJECT.*': 'SHORT FILM',\n",
    "    r'^DOCUMENTARY.*': 'DOCUMENTARY',\n",
    "    r'^CINEMATOGRAPHY.*': 'CINEMATOGRAPHY',\n",
    "    r'^ART DIRECTION.*': 'PRODUCTION DESIGN',\n",
    "    r'^DIRECTING.*': 'DIRECTING',\n",
    "    r'^SOUND.*': 'SOUND'\n",
    "}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cat_counts = clean_oscar_db['category'].value_counts(ascending=False)\n",
    "\n",
    "threshold = 50  # minder dan 50 nominaties worden in Other geplaatst\n",
    "clean_oscar_db['category'] = clean_oscar_db['category'].apply(\n",
    "lambda x: 'OTHER' if new_cat_counts[x] < threshold else x\n",
    ")\n",
    "\n",
    "new_cat_counts = clean_oscar_db['category'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cat_counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maak een horizontale barplot\n",
    "sns.barplot(x=new_cat_counts.values, y=new_cat_counts.index)\n",
    "plt.xlabel('Aantal nominaties')\n",
    "plt.ylabel('Categorieën')\n",
    "plt.title('Frequentie van Oscar-categorieën')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_category = clean_oscar_db.groupby('category')['winner'].value_counts().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_category.plot(kind='barh',\n",
    "                     title='Gewonnen oscars per categorie',\n",
    "                     stacked=True,\n",
    "                    xlabel='Aantal nominaties')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sommige categorieën komen vaker voor, maar het aantal gewonnen oscars is relatief hetzelfde voor elke catogorie.\n",
    "We nemen deze kolom dus niet mee in ons voorspelling model om ruis te voorkomen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Databases mergen\n",
    "\n",
    "We gaan de databases mergen op de 'movie_titel' tabel en de 'name' tabel. We joinen met 'left'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zet de datatypes om naar strings\n",
    "\n",
    "df_2 = dfr.copy()\n",
    "\n",
    "df_2['movie_title'] = df_2['movie_title'].astype(str)\n",
    "clean_oscar_db['film'] = clean_oscar_db['film'].astype(str) \n",
    "\n",
    "# Normaliseer de data\n",
    "df_2['movie_title'] = df_2['movie_title'].str.strip().str.lower()\n",
    "clean_oscar_db['film'] = clean_oscar_db['film'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_oscar_db['film'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['movie_title'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_2, clean_oscar_db, left_on='movie_title', right_on='film', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien veel NaN waardes bij de kolom film/winner/name. We kunnen er dus vanuit gaan dat deze films niet zijn genomineerd. Laten we een nieuwe categorie maken om dit duidelijk te maken. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voeg een nieuwe kolom toe voor de categorieën\n",
    "merged_df['oscar_categorie'] = merged_df['winner'].apply(\n",
    "    lambda x: 'Oscar gewonnen' if x == True else ('Oscar genomineerd' if x == False else 'Niet genomineerd')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laten we data nu visualiseren om een mooi beeld te krijgen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data visualiseren\n",
    "categorie_counts = merged_df['oscar_categorie'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(categorie_counts, labels=categorie_counts.index, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Verdeling van Oscar categorieën')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien hier dat slechts 13% van alle films in onze dataframe een Oscar wint. Laten we nu dieper in de data kijken waarom dit het geval zou kunnen zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check welke columns er zijn om mee te werken.\n",
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse van de IMDb-score: Kijk naar de gemiddelde IMDb-score per Oscar-status\n",
    "oscar_budget = merged_df.groupby('oscar_categorie')['budget'].mean()\n",
    "\n",
    "# Maak een bar chart voor de gemiddelde IMDb-score per Oscar-status\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(oscar_budget.index, oscar_budget, color=['red', 'orange', 'green'])\n",
    "plt.title('Gemiddelde budget per Oscar Status')\n",
    "plt.xlabel('Oscar Status')\n",
    "plt.ylabel('Gemiddelde budget')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieruit volgt dat de films die oscars hebben gewonnen gemiddeld een hoger budget hadden. Dit kan zeker invloed hebben op de kwaliteit van de film en welke acteurs ingehuurd kunnen worden. We kunnen deze kolom later gebruiken in ons voorspelling model. Laten we verder kijken in de data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse van de IMDb-score: Kijk naar de gemiddelde IMDb-score per Oscar-status\n",
    "imdb_by_status = merged_df.groupby('oscar_categorie')['imdb_score'].mean()\n",
    "\n",
    "# Maak een bar chart voor de gemiddelde IMDb-score per Oscar-status\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(imdb_by_status.index, imdb_by_status, color=['red', 'orange', 'green'])\n",
    "plt.title('Gemiddelde IMDb-score per Oscar Status')\n",
    "plt.xlabel('Oscar Status')\n",
    "plt.ylabel('Gemiddelde IMDb-score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien hier weer een verband, hoe hoger de IMDb-score des te meer oscars zijn gewonnen. Deze nemen we later dus ook mee in ons model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['genres'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['plot_keywords'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het leek leuk om te kijken of we misschien de plot konden gebruiken in onze prediction model, maar de cardinaliteit is veels te hoog van deze kolom. En er zit geen logische structuur in zoals bij genres.\n",
    "\n",
    "Om overfitten te voorkomen gaan we deze dus niet gebruiken in onze prediction model. Wel gaan we genres meenemen door eerst ze maar in max twee categorieën te plaatsen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse van regisseurs: Kijk naar het aantal Oscars gewonnen per regisseur\n",
    "director_awards= merged_df[merged_df['winner'] == True].groupby('director_name').size().sort_values(ascending=False)\n",
    "director_40= director_awards.head(40)\n",
    "# Maak een bar chart voor de top 10 regisseurs met de meeste Oscars gewonnen\n",
    "plt.figure(figsize=(12, 6))\n",
    "director_40.plot(kind='barh', color='purple')\n",
    "plt.title('Top 40 Regisseurs met de Meeste Oscars Gewonnen')\n",
    "plt.xlabel('Regisseur')\n",
    "plt.ylabel('Aantal Oscars Gewonnen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De regrisseur speelt zeker een rol in het behalen van een oscar. Van de gene die winnen hebben vele rond de 10 oscars gewonnen en we hebben er een paar, zoals Steven spielberg die ver boven het gemiddelde zitten. We gaan later het aantal oscars toevoegen per director in een nieuwe kolom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_by_content = merged_df.groupby(['content_rating','winner']).size().unstack()\n",
    "winner_by_content.plot(kind='barh',stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier zien we hetzelfde als bij de gewonnen oscars per categorie. Geen sterke verbanden, en allemaal relatief gezien even veel kans op een oscar. \n",
    "\n",
    "Ook deze tabel word later niet meegenomen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlatie bekijken\n",
    "Om goede correlaties te vinden checken we niet meer of een film ook was genomineerd. als het model tussen 3 categorieën moet zoeken word voorspellen lastig. Daarom gaan we bij merged simpelweg zeggen: Heeft het een oscar gewonnen ja of nee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verander de catogorie winner naar een numerieke waarde\n",
    "merged_df['oscar_won_numeric'] = merged_df['winner'].apply(lambda x: 1 if x == True else 0) \n",
    "\n",
    "# Selecteer de feature variables\n",
    "feat_columns = ['oscar_won_numeric', 'budget','imdb_score', 'duration', 'num_critic_for_reviews', 'num_voted_users', 'facenumber_in_poster', 'cast_total_facebook_likes',\n",
    "                   'num_user_for_reviews', 'director_facebook_likes', 'movie_facebook_likes', 'actor_1_facebook_likes', 'actor_2_facebook_likes', 'actor_3_facebook_likes']\n",
    "\n",
    "\n",
    "# Bereken de correlatiematrix\n",
    "correlation_matrix = merged_df[feat_columns].corr()\n",
    "\n",
    "# Plot de correlatiematrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot= True , cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlatiematrix van numerieke variabelen')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relatief slechte correlaties, voor KNN en Decision Tree maakt dit niet heel veel uit, aangezien ze ook verbanden kunnen vinden bij non lineaire verbindingen. Maar voor onze LogisticRegression is dit wel een probleem. \n",
    "\n",
    "Voor nu maken we dus 2 aparte features die we in de modellen stoppen. \n",
    "En voor de LR gebruiken we alleen correlaties boven de 0.1. Lagere correlaties dan dat kan wellicht leiden tot overfitten. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kolom toevoegen die bijhoudt hoeveel oscars een regrisseur heeft gewonnen. \n",
    "merged_df['director_oscar_count'] = merged_df['director_name'].map(director_awards).fillna(0)\n",
    "merged_df['director_oscar_count'].head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het is lastig om op naam te voorspellen, dus kijken we simpelweg hoeveel oscars een director heeft gewonnen voor ons voorspellingmodel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genres omzetten\n",
    "\n",
    "# Behoud maximaal 2 categorieen \n",
    "merged_df['cleaned_genres'] = merged_df['genres'].replace(\n",
    "    to_replace=r'^((\\w+)(\\|\\w+)?).*$',  # Match de eerste twee categorieën\n",
    "    value=r'\\1',  # Behoud alleen de eerste twee categorieën\n",
    "    regex=True  \n",
    ")\n",
    "print(merged_df[['genres', 'cleaned_genres']].head(40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummies maken van de genres\n",
    "genres_encoded = merged_df['cleaned_genres'].str.get_dummies(sep='|')\n",
    "merged_df = pd.concat([merged_df, genres_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu dat elke film maar in max twee categorieën kan zitten maken we er dummies. Deze kunnen we later in onze DT en KNN gebruiken om zo op categorie te kijken of het helpt met het voorspellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.plot_boxplots(merged_df,feat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nans opvullen met mediaan\n",
    "merged_df['budget'] = merged_df['budget'].fillna(merged_df['budget'].median())\n",
    "merged_df['duration'] = merged_df['duration'].fillna(merged_df['duration'].median())\n",
    "merged_df['num_user_for_reviews'] = merged_df['num_user_for_reviews'].fillna(merged_df['num_user_for_reviews'].median())\n",
    "merged_df['num_critic_for_reviews'] = merged_df['num_critic_for_reviews'].fillna(merged_df['num_critic_for_reviews'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We vullen hier de waardes op met de mediaan van hun kolom. In de boxplots zagen we dat de meeste films ongeveer dezelfde duur hebben, budget, en reviews. Dus vandaar onze keuze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modellen bouwen\n",
    "\n",
    "Laten we verschillende modellen bouwen. Nu dat we zagen dat we correlerende kolommen hadden kunnen we ook de optie gebruiken om lineaire regressie toe te passen. We gaan deze zometeen vergelijken met de Decision Tree, aangezien de latere ook goed werkt met categoriale data en minder lineair gerelateerde kolommmen.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features voor regressie model\n",
    "features_lr = [\n",
    "    'num_critic_for_reviews', 'num_voted_users', 'imdb_score',\n",
    "    'duration', 'num_user_for_reviews', 'movie_facebook_likes', 'director_oscar_count'\n",
    "]\n",
    "\n",
    "\n",
    "# Featrues voor Decision Tree\n",
    "features_dt = [\n",
    "    'num_critic_for_reviews', 'duration', 'num_voted_users', 'num_user_for_reviews', 'imdb_score', \n",
    "    'budget', 'director_oscar_count', 'movie_facebook_likes',\"Action\", \"Adventure\", \"Animation\", \"Biography\", \"Comedy\", \"Crime\", \"Documentary\", \"Drama\",\n",
    "    \"Family\", \"Fantasy\", \"Film\", \"Game\", \"History\", \"Horror\", \"Music\", \"Musical\", \"Mystery\",\n",
    "    \"News\", \"Romance\", \"Sci\", \"Short\", \"Sport\", \"Thriller\", \"War\", \"Western\"\n",
    "] # Alle , dummies\n",
    "\n",
    "# Features voor KNN\n",
    "features_knn = ['num_critic_for_reviews', 'duration', 'num_voted_users', 'num_user_for_reviews', 'imdb_score', \n",
    "    'budget', 'director_oscar_count', 'movie_facebook_likes'] # Zonder dummies\n",
    "\n",
    "target = merged_df['oscar_won_numeric'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train LR\n",
    "X_lr = merged_df[features_lr].astype(int)\n",
    "X_Lr_train, X_Lr_test, y_Lr_train, y_Lr_test = train_test_split(X_lr, target, test_size=0.2, random_state=42)\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_Lr_train, y_Lr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = np.arange(1, 50) # Dit bepaalt hoe diep/aantal buren ons model zal hebben voor zijn hyperparameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_Dt = merged_df[features_dt]\n",
    "X_Dt_train, X_Dt_test, y_Dt_train, y_Dt_test = train_test_split(X_Dt,  target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Maak arrays om elke waarde per diepte op te slaan\n",
    "test_Dt_accuracies = np.zeros(len(max_depths))\n",
    "test_Dt_rmse = np.zeros(len(max_depths))\n",
    "\n",
    "# Loop over de dieptes heen en maak een decision Tree voor elke diepte\n",
    "for i, d in enumerate(max_depths):\n",
    "    tree = DecisionTreeClassifier(max_depth=d, random_state=42)\n",
    "    tree.fit(X_Dt_train, y_Dt_train)\n",
    "    \n",
    "    # Accuracy berekenen\n",
    "    test_Dt_accuracies[i] = accuracy_score(y_Dt_test, tree.predict(X_Dt_test))\n",
    "    \n",
    "    # RMSE berekenen\n",
    "    test_Dt_rmse[i] = mean_squared_error(y_Dt_test, tree.predict(X_Dt_test), squared=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_knn = merged_df[features_knn]\n",
    "X_knn_train, X_knn_test, y_knn_train, y_knn_test = train_test_split(X_knn,  target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Maak een scaler aan voor de KNN\n",
    "scaler_knn = StandardScaler()\n",
    "X_knn_train_scaled = scaler_knn.fit_transform(X_knn_train)\n",
    "X_knn_test_scaled  = scaler_knn.transform(X_knn_test)\n",
    "\n",
    "test_Knn_accuracies = np.zeros(len(max_depths))\n",
    "test_Knn_rmse = np.zeros(len(max_depths))\n",
    "\n",
    "for i, k in enumerate(max_depths):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_knn_train_scaled, y_knn_train)\n",
    "    \n",
    "    # Accuracy berekenen\n",
    "    test_Knn_accuracies[i] = accuracy_score(y_knn_test, knn.predict(X_knn_test_scaled))\n",
    "    \n",
    "    # RMSE berekenen\n",
    "    test_Knn_rmse[i] = mean_squared_error(y_knn_test, knn.predict(X_knn_test_scaled), squared=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline vs Prediction\n",
    "Voor onze baseline pakken we het gemiddeld aantal gewonnen oscars en vergelijken het met onze voorspelling modellen. Uit de piechart zagen we dat ongeveer 13% van alle films een oscar wint, dus dat betekent dat onze modellen boven de 87% moeten scoren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_mean = merged_df['oscar_won_numeric'].mean() # Het gemiddelde aantal oscars die winnen nemen\n",
    "baseline_accuracy =  1 - baseline_mean\n",
    "print(\"Baseline Accuracy: \", round(baseline_accuracy * 100,2), '%')\n",
    "\n",
    "# Lr prediction\n",
    "y_Lr_pred = lr_model.predict(X_Lr_test)\n",
    "print(\"Logistic Regression Accuracy:\", round((accuracy_score(y_Lr_test, y_Lr_pred)*100),2), '%')\n",
    "\n",
    "# Dt prediction\n",
    "print(\"Decision Tree Accuracy:\", round(max(test_Dt_accuracies) * 100, 2), '% Met diepte', np.argmax(test_Dt_accuracies) + 1)\n",
    "\n",
    "# Knn prediction\n",
    "print(\"KNN Accuracy:\", round(max(test_Knn_accuracies) * 100,2), '% Met aantal buren', np.argmax(test_Knn_accuracies) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultaat van de modellen\n",
    "We zien hier dat de Decision Tree en KNN boven onze baseline scoren. En KNN heeft zelfs het hoogste gescoord met een buur aantal van 24. \n",
    "\n",
    "Laten we de data visualiseren om dieper op de data in te gaan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisatie van de modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelnamen en hun accuracies\n",
    "model_names = [\"Logistic Regression\", \"Decision Tree\", \"KNN\"]\n",
    "accuracies = [\n",
    "    accuracy_score(y_Lr_test, y_Lr_pred),\n",
    "    max(test_Dt_accuracies),  # Hoogste accuracy van Decision Tree met optimale hyperparameter\n",
    "    max(test_Knn_accuracies)  # Hoogste accuracy van KNN met optimale hyperparameter\n",
    "]\n",
    "\n",
    "# Plot maken\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(model_names, accuracies, color=['blue', 'green', 'red'])\n",
    "plt.axhline(y=baseline_accuracy, color='black', linestyle='--', label=\"Baseline Accuracy\")\n",
    "\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Vergelijking van Model Accuracies\")\n",
    "plt.ylim(0.8, 0.9)  # Schaal aanpassen zodat verschillen duidelijker zijn\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactieve functie\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "# Interactieve functie\n",
    "def plot_interactive(model_type, metric_type, selected_value):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    if model_type == 'Decision Tree':\n",
    "        x_values = max_depths\n",
    "        title = \"Decision Tree: Accuracy/RMSE vs Max Depth\"\n",
    "        label = f\"Selected Depth: {selected_value}\"\n",
    "        y_label = \"Accuracy (%)\" if metric_type == \"Accuracy\" else \"RMSE\"\n",
    "\n",
    "        if metric_type == \"Accuracy\":\n",
    "            y_values = [acc * 100 for acc in test_Dt_accuracies]\n",
    "            selected_y = test_Dt_accuracies[selected_value - 1] * 100\n",
    "        else:\n",
    "            y_values = test_Dt_rmse\n",
    "            selected_y = test_Dt_rmse[selected_value - 1]\n",
    "\n",
    "    elif model_type == 'KNN':\n",
    "        x_values = max_depths  # Gebruikt dezelfde max_depths voor een consistente slider\n",
    "        title = \"KNN: Accuracy/RMSE vs Number of Neighbors\"\n",
    "        label = f\"Selected Neighbors: {selected_value}\"\n",
    "        y_label = \"Accuracy (%)\" if metric_type == \"Accuracy\" else \"RMSE\"\n",
    "\n",
    "        if metric_type == \"Accuracy\":\n",
    "            y_values = [acc * 100 for acc in test_Knn_accuracies]\n",
    "            selected_y = test_Knn_accuracies[selected_value - 1] * 100\n",
    "        else:\n",
    "            y_values = test_Knn_rmse\n",
    "            selected_y = test_Knn_rmse[selected_value - 1]\n",
    "\n",
    "    # Plot de lijn + markers\n",
    "    fig.add_trace(go.Scatter(x=x_values, y=y_values, \n",
    "                             mode='lines+markers', \n",
    "                             name=f\"{model_type} {metric_type}\"))\n",
    "\n",
    "    # Markeer geselecteerde waarde\n",
    "    fig.add_trace(go.Scatter(x=[selected_value], y=[selected_y],\n",
    "                             mode='markers+text',\n",
    "                             marker=dict(color='red', size=10),\n",
    "                             text=[f\"{selected_y:.2f}\" if metric_type == \"RMSE\" else f\"{selected_y:.2f}%\"],\n",
    "                             textposition=\"top center\",\n",
    "                             name=label))\n",
    "\n",
    "    fig.update_layout(title=title,\n",
    "                      xaxis_title=\"Hyperparameter (Max Depth / Neighbors)\",\n",
    "                      yaxis_title=y_label,\n",
    "                      template=\"plotly_white\")\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# Widgets voor interactie\n",
    "interact(plot_interactive, \n",
    "         model_type=widgets.Dropdown(options=['Decision Tree', 'KNN'], value='Decision Tree', description=\"Model Type\"),\n",
    "         metric_type=widgets.Dropdown(options=['Accuracy', 'RMSE'], value='Accuracy', description=\"Metric\"),\n",
    "         selected_value=widgets.IntSlider(min=1, max=len(max_depths), step=1, value=1, description=\"Select Value\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusie onderzoeksvraag 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als antwoord op de onderzoeksvraag: Ja, het is zeker mogelijk om te voorspellen of een film een oscar wint of niet.\n",
    "Voor de meeste accuracay kun het KNN-model gebruiken met een score van 87.99%! Voor de hyperparameters geldt dat 18 buren het beste werkt.\n",
    "Voor de DT is het een diepte van 8. \n",
    "\n",
    "Door de lage correlatie scores zijn we niet verbaasd dat de logistische regressie minder goed heeft gescoord dan de rest, maar kwam alsnog aardig in de buurt. Voor nu is het duidelijk om te zien dat ookal is er een lage correlatie kunnen DT en KNN alsnog er goed scoren. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onderzoeksvraag 3: Hoe kunnen budget en omzet worden gebruikt om logische clusters van de films te vinden?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om clusters te bepalen in een dataset gaan we nu gebruik maken van unsupervised learning. De algoritmes die we gaan toepassen zijn KMeans en GMM.\n",
    "\n",
    "We maken een nieuw dataframe aan met 'gross' en 'budget'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gross_budget = dfr[['gross', 'budget']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bekijken hoeveel NaN values in de dataset voorkomen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gross_budget.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bekijken hoeveel rows het volledige df bevat. Als de NaN waardes maar een klein percentage van de volledige dataset bevat kunnen deze worden verwijderd. Als het een groot percentage bevat dan moeten we kijken of we dit logisch in kunnen vullen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = len(df_gross_budget)\n",
    "print(f'aantal rows in de totale datasframe: {total_rows}')\n",
    "nan_rows = df_gross_budget.isna().any(axis=1).sum()\n",
    "print(f'aantal nan rows in de totale datasframe: {nan_rows}')\n",
    "nan_percentage_rows = ((nan_rows / total_rows) * 100).round(1)\n",
    "print(f'Bevat NaN rows t.o.v. totale dataframe: {nan_percentage_rows}%')\n",
    "\n",
    "# Plotten\n",
    "labels = ['Rijen met NaN', 'Rijen zonder NaN']\n",
    "values = [nan_rows, total_rows - nan_rows]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(values, labels=labels, autopct='%1.1f%%', startangle=90, colors=['lightcoral', 'lightgreen'], explode=[0.1, 0])\n",
    "plt.title('Verdeling van rijen met en zonder NaN-waarden', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit is een aanzienlijk groot percentage NaN's. We gaan de data opvullen. Maar eerst moeten we bekijken welke kolommen uit de dataset het meest correleren. De kolommen die het meest correleren met gross en budget kunnen worden gebruikt om de missende data in te vullen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecteer numerieke kolommen voor correlatie analyse\n",
    "numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "correlation_matrix = df[numeric_columns].corr()\n",
    "\n",
    "# Plot correlatie heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, \n",
    "            annot=True,\n",
    "            cmap='coolwarm',\n",
    "            center=0,\n",
    "            fmt='.2f')\n",
    "plt.title('Correlatie tussen numerieke variabelen')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print de top 5 correlaties met budget en gross\n",
    "print(\"\\nTop 5 correlaties met budget:\")\n",
    "budget_correlations = correlation_matrix['budget'].sort_values(ascending=False)\n",
    "print(budget_correlations.head())\n",
    "\n",
    "print(\"\\nTop 5 correlaties met gross:\")\n",
    "gross_correlations = correlation_matrix['gross'].sort_values(ascending=False)\n",
    "print(gross_correlations.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De enige matige correlaties zijn tussen de gross en num_voted_users en num_users_for_reviews. We zullen deze 2 kolommen gebruiken om de missende NaN values in te vullen van gross. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vul missende waarden van 'gross' in op basis van gemiddelden per cluster\n",
    "# Cluster bepalen op basis van 'num_voted_users' en 'num_user_for_reviews'\n",
    "\n",
    "# Maak een nieuwe kolom voor clustering (bijvoorbeeld afronden van aantallen gebruikers)\n",
    "df['cluster'] = (\n",
    "    df['num_voted_users'].fillna(0).round(-3).astype(int).astype(str) + '_' +\n",
    "    df['num_user_for_reviews'].fillna(0).round(-2).astype(int).astype(str)\n",
    ")\n",
    "\n",
    "# Bereken gemiddelde 'gross' per cluster\n",
    "cluster_gross_mean = df.groupby('cluster')['gross'].mean()\n",
    "\n",
    "# Vul NaN-waarden van 'gross' in met de gemiddelden per cluster\n",
    "df['gross'] = df.apply(\n",
    "    lambda row: cluster_gross_mean[row['cluster']] if pd.isna(row['gross']) else row['gross'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Verwijder tijdelijke clusterkolom\n",
    "df.drop(columns=['cluster'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weer opnieuw een dataframe maken met alleen gross en budget maar dan met de ingevulde gross kolom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['gross', 'budget']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weer alle NaN values checken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opnieuw bekijken hoeveel procent NaN waarden bevat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = len(df)\n",
    "print(f'aantal rows in de totale datasframe: {total_rows}')\n",
    "nan_rows = df.isna().any(axis=1).sum()\n",
    "print(f'aantal nan rows in de totale datasframe: {nan_rows}')\n",
    "nan_percentage_rows = ((nan_rows / total_rows) * 100).round(1)\n",
    "print(f'Bevat NaN rows t.o.v. totale dataframe: {nan_percentage_rows}%')\n",
    "\n",
    "# Plotten\n",
    "labels = ['Rijen met NaN', 'Rijen zonder NaN']\n",
    "values = [nan_rows, total_rows - nan_rows]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(values, labels=labels, autopct='%1.1f%%', startangle=90, colors=['lightcoral', 'lightgreen'], explode=[0.1, 0])\n",
    "plt.title('Verdeling van rijen met en zonder NaN-waarden', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hebben het aantal NaN values verlaagd van 22.8% tot 10.1%. Dit is nogsteeds relatief veel maar helaas is er weinig correlatie met de budget kolom waardoor we deze niet verder in kunnen vullen. Daarom kiezen we ervoor om de resterende NaN waarden te verwijderen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle NaN's verwijderen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opnieuw bekijken hoeveel NaN's in de dataset voorkomen. Na het verwijderen ervan moeten ze voor allebei op 0 staan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het dataframe bekijken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verwijderen van outliers ##\n",
    "\n",
    "Omdat de modellen gevoelig zijn voor outliers gaan we identificeren welke we gaan verwijderen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.boxplot_gross_and_budget(df, 'gross')\n",
    "fn.histogram_gross(df, 'gross')\n",
    "\n",
    "fn.boxplot_gross_and_budget(df, 'budget')\n",
    "fn.histogram_gross(df, 'budget')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als we kijken naar een combinatie van de boxplots en histogrammen, dan zien we dat er extreme outliers in onze dataset voorkomen. Onze onderzoeksvraag vraagt niet om bijzondere gevallen te bepalen, maar om logische clusters te bepalen, wat na verwijderen van de outliers nogsteeds kan worden gedaan. Hierdoor besluiten we alle outliers te verwijderen uit onze dataset. Hierbij maken we gebruik van de functies uit functies.py. Ook bekijken we het aantal rijen en kolommen voordat we ze gaan verwijderen om te checken of ze echt zijn verwijderd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fn.remove_outliers(df, 'gross')\n",
    "df = fn.remove_outliers(df, 'budget')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checken of de outliers zijn verwijderd door het aantal rijen en kolommen te bekijken. Dit is inderdaad een lager getal dan eerst, wat betekend dat ze zijn verwijderd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ook bekijken we de histogrammen opnieuw. De x as moet een bereik hebben wat overeenkomt met wat we op de boxplots zagen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.histogram_gross(df, 'gross')\n",
    "fn.histogram_gross(df, 'budget')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het bereik op de x as komt inderdaad overeen met wat we zagen in de boxplots voordat we de outliers hebben verwijderd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu gaan we kijken of er na opvulling en opschoning van onze dataset logische clusters kunnen worden bepaald met unsupervised learning. De 2 modellen die we gebruiken zijn kmeans en gmm. We gebruiken deze 2 modellen omdat ze relatief eenvoudig, efficiënt en effectief zijn bij het vinden van clusters in onze continueu data. Kmeans kan goed voor bolvormige clusters modelleren en gmm kan goed verschillende vormen moddeleren doordat het flexibeler is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code afkomstig van les CM10\n",
    "# kMeans en GMM maken gebruik van afstandsmaten, daarom is standaardiseren belangrijk\n",
    "df.reset_index(inplace = True)\n",
    "\n",
    "# We passen scaling toe zodat de afstandmaten beter zijn verdeeld onder elkaar.\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df[['gross', 'budget']])\n",
    "df_z = pd.DataFrame(scaler.transform(df[['gross', 'budget']]), columns=['gross_z', 'budget_z'])\n",
    "df[['gross_z', 'budget_z']] = df_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kijken of de correcte kolommen zijn aangemaakt. gross_z en budget_z zijn inderdaad aangemaakt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moddeleren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gaan als eerst KMeans toepassen op onze dataset en bekijken welke clusters dit moddeleert. We kiezen hier handmatig 5 clusters. Dit doen we omdat onze hoofdvraag vraagt om 5 clusters: blockbuster films, flop films, cult films, mid range films en rest van de films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maken van een willekeurige clustering\n",
    "model_kMeans = KMeans(n_clusters=5, random_state=0)\n",
    "X_kMeans = df[['gross_z', 'budget_z']]\n",
    "\n",
    "# Clusters 'voorspellen' en opslaan\n",
    "prediction_kMeans = model_kMeans.fit_predict(X_kMeans)\n",
    "df['cluster_number'] = model_kMeans.predict(X_kMeans)\n",
    "\n",
    "# Plotten van 'omzet' en 'budget' en als kleur de clusters\n",
    "plt.scatter(df['gross'], df['budget'], c=df['cluster_number'], cmap='plasma')\n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(fn.euro_formatter))\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(fn.euro_formatter))\n",
    "plt.title('Scatterplot: omzet vs budget')\n",
    "plt.xlabel('omzet')\n",
    "plt.ylabel('budget')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als we naar de plot kijken zien we dat KMeans uitstekende logische clusters kan vormen. Alle kleuren staan gegroupeerd bij elkaar met logische parameters per groep. Helaas geeft dit geen clusters die overeenkomen met de 5 soorten films uit onze hoofdvraag. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om nog even bij KMeans te blijven gaan we hier de 'elbow method' toepassen. Dit doen we omdat dit het punt is waar het toevoegen van extra clusters nauwelijks meer leidt tot een significante verbetering in de clusteringkwaliteit. Als de 'knik' valt op 5 weten we dat dit het optimale punt is om te zoeken naar clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code afkomstig van les CM10\n",
    "\n",
    "data = []\n",
    "\n",
    "max_k = 20\n",
    "\n",
    "for i in range(1, max_k):\n",
    "    model_kMeans = KMeans(n_clusters=i, random_state=0)\n",
    "    X_kMeans = df[['gross_z', 'budget_z']]\n",
    "\n",
    "    # Clusters 'voorspellen' en opslaan\n",
    "    model_kMeans.fit(X_kMeans)\n",
    "\n",
    "    data.append([i, model_kMeans.score(X_kMeans)])\n",
    "\n",
    "df_plot_kmeans = pd.DataFrame(data, columns=['k', 'Score'])\n",
    "\n",
    "fig = plt.figure(figsize=(5,5), dpi=150)\n",
    "\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.set(xlim=(0,max_k),\n",
    "       xlabel='n',\n",
    "       ylabel='Score',\n",
    "       title='Kmeans: score vs k')\n",
    "\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(max_k))\n",
    "ax.ticklabel_format(useOffset=False)\n",
    "ax.plot(df_plot_kmeans['k'], df_plot_kmeans['Score'], '-o')\n",
    "\n",
    "ax.legend(['k'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als we kijken naar de plot van de 'elbow method' zien we dat de 'knik' zit bij n=2. Dit punt geeft de optimale balans in modelcomplexiteit en clusteringkwaliteit. De knik valt dus niet op 5, wat betekend dat we eerder met n=5 hebben overclusterd. Dit betekent niet dat het geen logische clusters heeft gevonden, maar wel dat het overcomplexe clusters probeert te vinden zonder dat de kwaliteit van de clusters omhoog gaat. Hieronder plotten we de optimale balans met n=2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maken van een willekeurige clustering\n",
    "model_kMeans = KMeans(n_clusters=2, random_state=0)\n",
    "X_kMeans = df[['gross_z', 'budget_z']]\n",
    "\n",
    "# Clusters 'voorspellen' en opslaan\n",
    "prediction_kMeans = model_kMeans.fit_predict(X_kMeans)\n",
    "df['cluster_number'] = model_kMeans.predict(X_kMeans)\n",
    "\n",
    "# Plotten van 'omzet' en 'budget' en als kleur de clusters\n",
    "plt.scatter(df['gross'], df['budget'], c=df['cluster_number'], cmap='plasma')\n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(fn.euro_formatter))\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(fn.euro_formatter))\n",
    "plt.title('Scatterplot: omzet vs budget')\n",
    "plt.xlabel('omzet')\n",
    "plt.ylabel('budget')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ook dit geeft weer logische clusters zoals laag budget en omzet en hoog budget en omzet, maar geen clusters die slaan op onze hoofdvraag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu gaan we hetzelfde doen maar dan met GMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maken van een willekeurige clustering\n",
    "model_gmm = gmm(n_components=5, random_state=0)\n",
    "X_gmm = df[['gross_z', 'budget_z']]\n",
    "\n",
    "# Clusters 'voorspellen' en opslaan\n",
    "prediction_gmm = model_gmm.fit_predict(X_gmm)\n",
    "df['cluster_number'] = model_gmm.predict(X_gmm)\n",
    "\n",
    "# Plotten van 'omzet' en 'budget' en als kleur de clusters\n",
    "plt.scatter(df['gross'], df['budget'], c=df['cluster_number'], cmap='plasma')\n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(fn.euro_formatter))\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(fn.euro_formatter))\n",
    "plt.title('Scatterplot: omzet vs budget')\n",
    "plt.xlabel('omzet')\n",
    "plt.ylabel('budget')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ook hier zie je dat het clusters maakt die logisch zijn maar weer niet slaan op onze hoofdvraag. De vormen zijn wat flexibeler en rondvormig, wat een kenmerk is van gmm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dan gaan we kijken naar de elbow method voor gmm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code afkomstig van les CM10\n",
    "data = []\n",
    "\n",
    "max_n = 20\n",
    "\n",
    "for i in range(1, max_k):\n",
    "    model_gmm = gmm(n_components=i, random_state=0)\n",
    "    X_gmm = df[['gross_z', 'budget_z']]\n",
    "\n",
    "    prediction_gmm = model_gmm.fit(X_gmm)\n",
    "    data.append([i, model_gmm.score(X_gmm)])\n",
    "\n",
    "df_plot_gmm = pd.DataFrame(data, columns=['n', 'Score'])\n",
    "\n",
    "fig = plt.figure(figsize=(5,5), dpi=150)\n",
    "\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.set(xlim=(0,max_n),\n",
    "       xlabel='n',\n",
    "       ylabel='Score',\n",
    "       title='GMM: score vs n')\n",
    "\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(20))\n",
    "ax.ticklabel_format(useOffset=False)\n",
    "ax.plot(df_plot_gmm['n'], df_plot_gmm['Score'], '-o')\n",
    "\n",
    "ax.legend(['n'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De knik bij de elbow method voor gmm zit op 4. Dit punt geeft de optimale balans in modelcomplexiteit en clusteringkwaliteit. De knik valt dus niet op 5, wat betekend dat we eerder met n=5 hebben overclusterd. Dit betekent niet dat het geen logische clusters heeft gevonden, maar wel dat het overcomplexe clusters probeert te vinden zonder dat de kwaliteit van de clusters omhoog gaat. Zeker bij deze want hier flatlined de plot tussen 4 en 5. Hieronder plotten we de optimale balans met n=4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maken van een willekeurige clustering\n",
    "model_gmm = gmm(n_components=4, random_state=0)\n",
    "X_gmm = df[['gross_z', 'budget_z']]\n",
    "\n",
    "# Clusters 'voorspellen' en opslaan\n",
    "prediction_gmm = model_gmm.fit_predict(X_gmm)\n",
    "df['cluster_number'] = model_gmm.predict(X_gmm)\n",
    "\n",
    "# Plotten van 'omzet' en 'budget' en als kleur de clusters\n",
    "plt.scatter(df['gross'], df['budget'], c=df['cluster_number'], cmap='plasma')\n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(fn.euro_formatter))\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(fn.euro_formatter))\n",
    "plt.title('Scatterplot: omzet vs budget')\n",
    "plt.xlabel('omzet')\n",
    "plt.ylabel('budget')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ook hier zie je dat het clusters maakt die logisch zijn maar weer niet slaan op onze hoofdvraag. De logische clusters hebben allemaal dezelfde combinatie van hoeveelheid in budget en omzet. De vormen zijn wat flexibeler en rondvormig, wat een kenmerk is van gmm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natuurlijk zouden we dit zelf wel kunnen maken op basis van een paar regels, namelijk:\n",
    "\n",
    "Het opdelen van de films in 5 categorieën.\n",
    "\n",
    "1. Blockbuster: hoog budget met hoge omzet\n",
    "2. Flop: hoog budget met lage omzet\n",
    "3. Cultfilm: laag budget met hoge omzet\n",
    "4. Mid-Range Movie: Gemiddeld budget met gemiddelde omzet\n",
    "5. Average: Alle andere gevallen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In volledige dataFrame, alle NaN waarde verwijderen van budget en gross.\n",
    "df = dfr[['budget', 'gross']].dropna()\n",
    "\n",
    "# Extreme waarde van budget en gross worden ook verwijderd.\n",
    "df = df[(df['budget'] < 350000000) & (df['gross'] < 1000000000)] \\\n",
    "\n",
    "# Zie functies.py voor de functie classify_movie\n",
    "df['Category'] = df.apply(fn.classify_movie, axis=1)\n",
    "\n",
    "# Scatterplot Visualiseren met kleur\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = {'Blockbuster':'green', 'Flop':'red', 'Cultfilm':'blue', 'Average':'orange', 'Mid-Range Movie':'purple'}\n",
    "scatter = plt.scatter(df['budget'], df['gross'], \n",
    "                      c=df['Category'].map(colors), alpha=0.5, s=60, edgecolor='k', marker='o')\n",
    "\n",
    "# Titel en labels\n",
    "plt.title('Filmclusters Gebaseerd op gudget en winst', fontsize=16)\n",
    "plt.xlabel('Budget (in dollars)', fontsize=14)\n",
    "plt.ylabel('Omzet (in dollars)', fontsize=14)\n",
    "\n",
    "# Weergavegrenzen\n",
    "plt.xlim(0, 300000000)  \n",
    "plt.ylim(0, 800000000) \n",
    "\n",
    "# Grafiek lijn\n",
    "plt.grid(True, linestyle='-', alpha=0.5)\n",
    "\n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(fn.euro_formatter))\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(fn.euro_formatter))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kleur en kermerken van de clusters in de scatterplot**\n",
    "\n",
    "- **Groen: blockbuster films**\n",
    "\n",
    "Deze films zijn met een hoog budget (> 100 miljoen dollar) en met een hoge omzet (>300 miljoen dollar).\n",
    "\n",
    "We zien groene cluster rechterboven in de grafiek. De succesvolle films.\n",
    "\n",
    "\n",
    "- **Rood: flop films**\n",
    "\n",
    "Deze films zijn met een hoog budget (> 100 miljoen dollar) en met een lage omzet (<50 miljoen dollar).\n",
    "\n",
    "We zien rode cluster rechtsonder in de grafiek. Deze is een klein cluster.\n",
    "\n",
    "\n",
    "- **Blauw: cultfilms**\n",
    "\n",
    "Deze films zijn met een laag budget (<20 miljoen dollar) en met een relatief hoge omzet (>50 miljoen dollar).\n",
    "\n",
    "We zien blauwe cluster linkerboven in de grafiek. Dit cluster laten zien de films met een laag budget toch tot een groot succes kan zijn.\n",
    "\n",
    "\n",
    "- **Paars: mid range films**\n",
    "\n",
    "Deze films zijn met een middelgroot budget (50-100 miljoen dollar) en met een middelgroot omzet (50-300 miljoen dollar).\n",
    "\n",
    "We zien paarse cluster midden in de grafiek. Deze is een groot cluster, betekent er zijn heel veel prima films.\n",
    "\n",
    "\n",
    "- **Orange: rest van de films**\n",
    "\n",
    "Alle film die niet in bovenstaande categorieën.\n",
    "\n",
    "We zien orange cluster verspreid over de grafiek. Er zijn heel veel films die gewoon middelmatige resultaten halen, dus niet te ondersheiden in budget of omzet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusie onderzoeksvraag 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Door middel van unsupervised learning kunnen er logische clusters gemaakt worden. Alle 2 de modellen presteren hier goed in. De kleuren zijn niet verspreid van elkaar wat dit aanduidt. Er is echter geen goed onderscheid te maken tussen blockbusters, flops en cultfilms als je kijkt naar de kleuren van de clusters. Zelfs met verschillende k waarden van beide modellen wordt het er niet beter op.\n",
    "\n",
    "We kunnen wel door middel van rule based tabellen een logische cluster maken. Maar goed, dat is supervised en niet unsupervised learning.\n",
    "\n",
    "Het is dus mogelijk om logische clusters te vinden met onze unsupervised technieken, maar deze kunnen geen onderscheid vinden tussen de 5 verschillende films."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
