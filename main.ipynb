{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Film Casus\n",
    "\n",
    "Welkom bij het onderzoek van Team 1! \n",
    "\n",
    "- Gemaakt door Yula, Joel en Pim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "In dit project gaan wij 2 filmdatasets onderzoeken. \n",
    "\n",
    "Voor dat we gaan beginnen gaan we eerste nog **data begrijpen** en **data voorbereiden**.\n",
    "\n",
    "We beantwoorden totaal 3 onderzoeksvragen：\n",
    "1. In hoeverre is de omzet van een film te voorspellen op basis van de populariteit op Facebook en IMDB？\n",
    "2. Is het mogelijk om te voorspellen of een film een oscar zal winnen of niet?\n",
    "3. Hoe kunnen budget en omzet worden gebruikt om logische clusters van de films te vinden?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "**Alle imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functies as fn\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "from sklearn.mixture import GaussianMixture as gmm\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Laad de dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = pd.read_csv('data/movie-1.csv')\n",
    "\n",
    "# Toon de maximale informatie die de dataframe kan geven.\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Formatteer alle grote getallen voor een betere leesbaarheid.\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kopie van de dataset**\n",
    "\n",
    "\n",
    "Een kopie van de gegevens maken om mee te werken,\n",
    "zodat we het oorspronkelijke dataset niet wijzigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfr.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Een kijkje nemen naar de gegevens die we hebben gekregen.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Haal de kolomnamen op om te zien met wat voor soort variabelen we werken**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meetniveaus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename=\"meetniveaus.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Doel- en kenmerkenvariabelen**\n",
    "\n",
    "\n",
    "De target variabel is al gegeven, namelijk de 'gross' kolom.\n",
    "\n",
    "De gross is afhankelijk van de feature variables, die zijn onafhankelijk.\n",
    "\n",
    "We hebben gekozen voor deze feature variabelen omdat deze kolommen het best passen bij onze onderzoeksvraag. \n",
    "\n",
    "We moeten het voorspellen aan de hand van de populariteit van facebook en IMDB. Ofwel de statistieken van deze 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureVariables = ['director_facebook_likes', \n",
    "                    'actor_1_facebook_likes', \n",
    "                    'actor_2_facebook_likes', \n",
    "                    'actor_3_facebook_likes', \n",
    "                    'cast_total_facebook_likes', \n",
    "                    'movie_facebook_likes', \n",
    "                    'imdb_score']\n",
    "\n",
    "targetVariable = ['gross']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Maak een andere dataframe met alleen de kolommen waarin we geïnteresseerd zijn.**\n",
    "\n",
    "Door alleen deze te nemen, gaat onze dataset van 28 naar 8 kolommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape) #check impact\n",
    "df = df[featureVariables + targetVariable]\n",
    "print(df.shape) #check impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Controleer NaN-waarden**\n",
    "\n",
    "Verwijder voorlopig alle NaN-waarden in de kenmerken- en doelvariabelen. Later zullen we verder onderzoeken hoe we deze op de juiste manier kunnen verwerken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zullen alle NaN-waarden verwijderen. We kunnen ze niet vervangen, omdat de meerderheid onze doelvariabele bevat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape) #check impact\n",
    "df = df.dropna()\n",
    "print(df.shape) #check impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nu zullen we alle kolommen analyseren om te controleren op anomalieën.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle statistieken zien er schoon uit.\n",
    "\n",
    "Alle kolommen met 'namen' bevatten NaN en getallen waar dit verwacht wordt.\n",
    "\n",
    "Alle kolommen met 'likes' bevatten NaN en een getal waar dit verwacht wordt. Ook geen vreemde minimale of maximale waarden.\n",
    "\n",
    "De kolom 'imdb_score' heeft alleen waarden tussen 0 en 10, wat verwacht wordt.\n",
    "\n",
    "En tot slot heeft de kolom 'gross' een natuurlijke orde van grootte van min tot max."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FeatureVariables met histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms(df, featureVariables):\n",
    "    num_features = len(featureVariables)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_features, figsize=(5 * num_features, 6), sharey=False)\n",
    "\n",
    "    for i, feature in enumerate(featureVariables):\n",
    "        sns.histplot(data=df, x=feature, kde=True, bins=20, color=\"skyblue\", ax=axes[i])\n",
    "\n",
    "    plt.suptitle(\"Histograms of Feature Variables\", y=1.02, fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "plot_histograms(df, featureVariables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**imdb_score**\n",
    "\n",
    "De verdeling van deze featureVariabele is relatief normaal verdeeld, wat betekent dat de meeste films een IMDb-score tussen 5 en 7 hebben.\n",
    "\n",
    "**Andere Variabelen met likes**\n",
    "\n",
    "Veel van deze featureVariabelen hebben een scheve verdeling, waarbij de meeste films weinig likes hebben en een paar films veel likes. Dit kan zijn door heel bekend regisseurs en acteurs in bepaald films."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featurevariables met boxplots en uitschieters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zullen geen van de uitschieters uit onze doelvariabele 'gross' verwijderen. Voor onze kenmerkenvariabelen zijn er echter enkele vreemde uitschieters en veel regisseurs en acteurs met 0 likes op Facebook. \n",
    "\n",
    "Er is super veel variatie tussen alle feature variabelen. Wij verwachten dat films met een hoge like score op alle gebieden, hoger zal scoren in hun omzet. Dus Wij zullen geen uitschieters verwijderen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxplots(df, featureVariables):\n",
    "    num_features = len(featureVariables)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_features, figsize=(5 * num_features, 6), sharey=True)\n",
    "\n",
    "    for i, feature in enumerate(featureVariables):\n",
    "        sns.boxplot(data=df, x=feature, ax=axes[i])\n",
    "\n",
    "\n",
    "    plt.suptitle(\"Boxplots of Feature Variables\", y=1.02, fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "plot_boxplots(df, featureVariables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**imdb_score**\n",
    "\n",
    "Deze featureVariabel heeft geen duidelijke outliers. Dit maakt het betrouwbaarder en gemakkelijker te gebruiken in onze modellen.\n",
    "\n",
    "**Andere Variabelen met likes**\n",
    "\n",
    "Zoals wij bij histogram hebben gezien, veel van deze featureVariabelen hebben een scheve verdeling, waardoor modellen mogelijk worden beïnvloed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlatie tussen TargetVariable en FeatureVariables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gaan hier met scatterplots onderzoeken wat de relatie is tussen het aantal Facebook-likes van de regisseur, de acteurs, de film, de IMDb-score en de hele cast en de totale opbrengst van de film."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scatterplots**\n",
    "\n",
    "Bereken de feature variabelen tegenover de doelvariabele, zodat we kunnen zien welke kenmerken (enigszins) belangrijk zijn voor de doelvariabele\n",
    "\n",
    "Zoals je kunt aflezen is er geen enkele feature variabele die met zekerheid een positieve correlatie heeft. De hoogste heeft een 0.38 wat maar een matige positieve correlatie weergeeft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = df[featureVariables + targetVariable].corr()['gross'].sort_values(ascending=False)\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.pairgrid_plot(df, featureVariables, targetVariable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resultaat**\n",
    "\n",
    "Deze plot toont de relatie tussen de targetvariabele gross en de verschillende featurevariabelen. De **blauwe punten** zijn de gegevenspunten en de **rode lijn** is een lineaire regressielijn. Hoe schuiner de lijn, hoe hoger de correlatie tussen beide kenmerken.\n",
    "\n",
    "We zien duidelijk dat een stijgende rode lijn, zoals bij movie_facebook_likes, een positieve relatie heeft. Dit klopt ook, want movie_facebook_likes heeft een positieve correlatie van 0,38.\n",
    "\n",
    "Bij een vlakke lijn, zoals bij director_facebook_likes, is er een zwakke of bijna geen relatie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onderzoeksvraag 1: In hoeverre is de omzet van een film te voorspellen op basis van de populariteit op Facebook en IMDB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modellen ##\n",
    "\n",
    "Hier gaan we de modellen toepassen op onze data. \n",
    "\n",
    "Als eerst gaan we een train test split maken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[featureVariables]\n",
    "y = df[targetVariable]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "\n",
    "Een baseline score is nodig om te kijken hoe ver onze modellen hiervan afwijken. Als de score van ons complexere model eronder zit doet het model het beter dan de baseline model wat goed is, als de score erboven zit doet het model het slechter en is dit een reden om dat model niet te gaan gebruiken.\n",
    "\n",
    "De baseline bereken je met de 'mean_squared_error' uitgedrukt in RMSE. \n",
    "\n",
    "De baseline score geeft ons een referentie voor onze modelprestaties. Elk model dat op zijn minst beter presteert dan deze baseline is een verbetering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dit gemiddelde word als de \"baseline\" voorspelling gebruikt voor alle tests.\n",
    "baseline = np.mean(y_train)\n",
    "\n",
    "# Dit betekent dat elke voorspelling hetzelfde is en gelijk is aan het gemiddelde van y_train.\n",
    "y_pred = np.ones(len(X_test)) * baseline\n",
    "\n",
    "# 'squared=False' geeft aan dat de wortel van de mean squared errror word genomen, zodat je de RMSE krijgt.\n",
    "baseline_score = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "print(f\"RMSE: {baseline_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linieare Regressie\n",
    "\n",
    "Als eerst gaan we linieare regressie toepassen. \n",
    "\n",
    "De data gaan we ook normaliseren. Normaliseren is nodig om het linieare regressie model beter te laten werken omdat het model werkt op relatieve afstanden van elkaar.\n",
    "\n",
    "Bij dit model hebben we niet gekozen voor hyperparameters, dit model is vrij simpel en geeft alleen een directe oplossing door de normale vergelijking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Een genormaliseerde train en test maken\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maak een lineaire regressie model aan\n",
    "lr = lm.LinearRegression()\n",
    "\n",
    "# Fit het model met de trainings data\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Bereken de voorspellingen voor de test data\n",
    "y_pred = lr.predict(X_test_scaled)\n",
    "\n",
    "# Bereken de RMSE\n",
    "lr_score = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f\"Root Mean Squared Error: {lr_score:.2f}\")\n",
    "\n",
    "# Bereken de R^2 score voor het regressiemodel\n",
    "lr_r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {lr_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De uitkomst van dit model is 58977858.91 en zit met 14,94% onder het baseline model wat goed is.\n",
    "\n",
    "De R-squared is 0.29. Dit model kan ongeveer 29% van de variatie in de variabele kan verklaren. \n",
    "\n",
    "Dit is niet al te best. Dit duid op een niet linieare relatie. (dit hadden we ook gezien bij de correlatie plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN\n",
    "\n",
    "Hier gaan we KNN toepassen. De hyperparameters zijn n_neighbors=15, weights=\"distance\", p=2.\n",
    "\n",
    "We hebben gekozen voor N_neighbors=15 want uit code blijkt beste aantal buren is gelijk aan 15.\n",
    "\n",
    "Ook hebben we gekozen voor p=2. Dit neemt de euclidische afstand, ipv p=1 de minkowski afstand. Dit geeft voor onze dataset het beste resultaat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code uit de les van CM09\n",
    "data = []\n",
    "\n",
    "max_n = 15\n",
    "\n",
    "for i in range(1, max_n + 1):\n",
    "    knn = KNeighborsRegressor(n_neighbors=i, weights=\"distance\", p=2)\n",
    "\n",
    "    # Fitten met trainingsdaata\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Bereken de voorspellingen\n",
    "    y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "    # Bereken de RMSE\n",
    "    knn_score = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "    data.append([i, knn_score])\n",
    "\n",
    "\n",
    "df_knn = pd.DataFrame(data, columns=['n', 'RMSE'])\n",
    "\n",
    "fig = plt.figure(figsize=(6,5), dpi=150)\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.set(xlim=(1,max_n),\n",
    "       xlabel='Aantal buren (n)',\n",
    "       ylabel='RMSE',\n",
    "       title='KNN: score vs n')\n",
    "\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(15))\n",
    "ax.ticklabel_format(useOffset=False)\n",
    "ax.plot(df_knn['n'], df_knn['RMSE'], '-o')\n",
    "\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(fn.euro_formatter))\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beste aantal buren berekenen\n",
    "best_n = None\n",
    "best_rmse = float('inf')\n",
    "\n",
    "for index, row in df_knn.iterrows():\n",
    "    if row['RMSE'] < best_rmse:\n",
    "        best_n = row['n']\n",
    "        best_rmse = row['RMSE']\n",
    "\n",
    "print(f\"Beste n: {int(best_n)} met RMSE = {best_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN regressie model met hyperparameters\n",
    "knn = KNeighborsRegressor(n_neighbors=int(best_n), weights=\"distance\", p=2)\n",
    "\n",
    "# Fitten met trainingsdaata\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Bereken de voorspellingen\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "# Bereken de RMSE\n",
    "knn_score = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f\"Root Mean Squared Error: {knn_score:.2f}\")\n",
    "\n",
    "# Bereken de R^2 score voor het KNN model\n",
    "knn_r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {knn_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De uitkomst van dit model is 58.339.596,58, wat 16,37% onder het baseline model ligt, wat goed is. \n",
    "\n",
    "De R-squared waarde is 0,30, wat aangeeft dat dit model ongeveer 30% van de variatie in de afhankelijke variabele kan verklaren, wat nog steeds niet goed genoeg is. \n",
    "\n",
    "Dit wijst op een niet-lineaire relatie tussen de variabelen (dit was ook te zien in de correlatieplots)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor\n",
    "\n",
    "We passen nu een decision tree regressor toe. Deze keuze hebben we gemaakt omdat deze beter om zou moeten kunnen gaan met niet lineare verbanden. \n",
    "\n",
    "Wat goed uitkomt want uit ons correlatie onderzoek is een slechte correlatie gekomen. \n",
    "\n",
    "We hoeven ook geen gebruik te maken van een scalar om te normaliseren. Een DTR kan hiermee omgaan.\n",
    "\n",
    "We gebruiken max_depth=4 omdat dit het 'beste' model is wat we hebben. Zelfs door veel verder te gaan in de boom wordt de score alleen maar slechter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitsen in train en test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[featureVariables], df[targetVariable], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "max_depth = 15\n",
    "\n",
    "for i in range(1, max_depth + 1):\n",
    "    # DTR met alle max_depths\n",
    "    tree = DecisionTreeRegressor(max_depth=i, random_state=42)\n",
    "    \n",
    "    # Fitten met niet gescalede data\n",
    "    tree.fit(X_train, y_train)\n",
    "    \n",
    "    # Bereken de voorspellingen\n",
    "    y_pred = tree.predict(X_test)\n",
    "    \n",
    "    # Bereken de RMSE\n",
    "    tree_score = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    \n",
    "    data.append([i, tree_score])\n",
    "\n",
    "df_tree = pd.DataFrame(data, columns=['max_depth', 'RMSE'])\n",
    "\n",
    "# Plotten van de resultaten\n",
    "fig = plt.figure(figsize=(5, 5), dpi=150)\n",
    "ax = plt.axes()\n",
    "\n",
    "# Instellen van de plotlimieten en labels\n",
    "ax.set(xlim=(1, max_depth),\n",
    "       xlabel='max_depth',\n",
    "       ylabel='RMSE',\n",
    "       title='Decision Tree: RMSE vs max_depth')\n",
    "\n",
    "ax.plot(df_tree['max_depth'], df_tree['RMSE'], '-o')\n",
    "\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(fn.euro_formatter))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regressor initialiseren en trainen\n",
    "tree_regressor = DecisionTreeRegressor(max_depth=4,random_state=42)\n",
    "tree_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Voorspellingen doen op de test set\n",
    "y_pred = tree_regressor.predict(X_test)\n",
    "\n",
    "# Evaluatie van het model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "tree_score = mse ** 0.5\n",
    "print(f\"Root Mean Squared Error (RMSE): {tree_score:.2f}\")\n",
    "\n",
    "# Bereken de R^2 score voor het Decision Tree model\n",
    "tree_r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {tree_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De uitkomst van dit model is 62424735.88, wat met 10,52% boven het baseline model zit wat goed is. \n",
    "\n",
    "Een R-squared van 0.19 wat aangeeft dat dit model ongeveer 19% van de variatie in de variabele kan verklaren wat slecht is. \n",
    "\n",
    "Dit is niet al te best. Dit duid op een niet linieare relatie. (dit hadden we ook gezien bij de correlatie plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusie onderzoeksvraag 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  samenvatting van alle resultaten uit modellen\n",
    "results = []\n",
    "\n",
    "results.append(['Linear Regression', lr_score, lr_r2])\n",
    "results.append(['KNN Regression', knn_score, knn_r2])\n",
    "results.append(['Decision Tree Regression', tree_score, tree_r2])\n",
    "\n",
    "df_results = pd.DataFrame(results, columns=['Model', 'RMSE', 'R²'])\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Het KNN model** doet het iets beter dan lineaire regressie, maar het verschil is klein. Het KNN model werkt ook beter dan het baseline model en het beslissingsboommodel (DTR). \n",
    "\n",
    "Het KNN model heeft R² = 0.30, wat ook niet goed is en betekent dat het model maar 30% van de verschillen in omzet kan verklaren.\n",
    "\n",
    "**Hiermee concluderen we dat de omzet van een film niet te voorspellen is op basis van de populariteit op facebook en IMDB.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onderzoeksvraag 2: Is het mogelijk om te voorspellen of een film een oscar zal winnen of niet?\n",
    "\n",
    "Een oscar winnen is een hele eer in de filmindustrie. Het is dus zeer interessant of we wellicht een model kunnen bouwen welke film een oscar zou winnen of niet. Wellicht kunnen we zo een accuraat model bouwen dat het miljarden waard zou zijn. En aangezien elke regrisseur die gefocust is op roem dit graag zou willen weten. Laten we van start gaan! En wellicht rijk worden!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inladen db\n",
    "\n",
    "oscar_db = pd.read_csv('data/the_oscar_award.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check of alles correct is ingeladen\n",
    "\n",
    "oscar_db.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien hier 7 tabellen terug de Target waarop wij gaan focussen is de 'Winner' tabel. Daarin kunnen we zien of een film een oscar heeft gewonnen of niet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oscar_db.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieruit volgt dat tabel 'ceremony' gewoonweg bijhoudt hoeveel keer de oscar awards zijn gehouden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oscar_db.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check hoeveel True en False er zijn in de Winner tabel\n",
    "true_count = oscar_db['winner'].value_counts()[True]\n",
    "false_count = oscar_db['winner'].value_counts()[False]\n",
    "\n",
    "# Benaming voor de taart diagram\n",
    "labels = ['Won Oscar', 'Did Not Win Oscar']\n",
    "\n",
    "# Data om te plotten\n",
    "sizes = [true_count, false_count]\n",
    "\n",
    "# Maak taart diagram\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=['lightblue', 'lightcoral'])\n",
    "plt.title('Oscar Wins Distribution')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien dus dat minder dan een vierde van de genomineerde een Oscar wint. Maar waar we natuurlijk ook naar moeten kijken is hoe groot de kans is om uberhaupt genomineerd te worden. Daarvoor zullen we de 2 datasets moeten mergen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Databases mergen\n",
    "\n",
    "We gaan de databases mergen op de 'movie_titel' tabel en de 'name' tabel. We joinen met 'left'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zet de datatypes om naar strings\n",
    "\n",
    "dfr['movie_title'] = dfr['movie_title'].astype(str)\n",
    "oscar_db['film'] = oscar_db['film'].astype(str) \n",
    "\n",
    "# Normaliseer de data\n",
    "dfr['movie_title'] = dfr['movie_title'].str.strip().str.lower()\n",
    "oscar_db['film'] = oscar_db['film'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oscar_db['film'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr['movie_title'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(dfr, oscar_db, left_on='movie_title', right_on='film', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien veel NaN waardes bij de kolom film/winner/name. We kunnen er dus vanuit gaan dat deze films niet zijn genomineerd. Laten we een nieuwe categorie maken om dit duidelijk te maken. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voeg een nieuwe kolom toe voor de categorieën\n",
    "merged_df['categorie'] = merged_df['winner'].apply(\n",
    "    lambda x: 'Oscar gewonnen' if x == True else ('Oscar genomineerd' if x == False else 'Niet genomineerd')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laten we data nu visualiseren om een mooi beeld te krijgen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data visualiseren\n",
    "categorie_counts = merged_df['categorie'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(categorie_counts, labels=categorie_counts.index, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Verdeling van Oscar categorieën')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien hier dat slechts 13% van alle films in onze dataframe een Oscar wint. Laten we nu dieper in de data kijken waarom dit het geval zou kunnen zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check welke columns er zijn om mee te werken.\n",
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse van het budget: Kijk naar het gemiddelde budget per Oscar-status\n",
    "budget_by_status = merged_df.groupby('categorie')['budget'].mean()\n",
    "\n",
    "# Maak een bar chart voor het gemiddelde budget per Oscar-status\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(budget_by_status.index, budget_by_status, color=['red', 'orange', 'green'])\n",
    "plt.title('Gemiddeld Budget per Oscar Status')\n",
    "plt.xlabel('Oscar Status')\n",
    "plt.ylabel('Gemiddeld Budget')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieruit volgt dat de films die oscars hebben gewonnen gemiddeld een hoger budget hadden. Dit kan zeker invloed hebben op de kwaliteit van de film en welke acteurs ingehuurd kunnen worden. Laten we verder kijken in de data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse van de IMDb-score: Kijk naar de gemiddelde IMDb-score per Oscar-status\n",
    "imdb_by_status = merged_df.groupby('categorie')['imdb_score'].mean()\n",
    "\n",
    "# Maak een bar chart voor de gemiddelde IMDb-score per Oscar-status\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(imdb_by_status.index, imdb_by_status, color=['red', 'orange', 'green'])\n",
    "plt.title('Gemiddelde IMDb-score per Oscar Status')\n",
    "plt.xlabel('Oscar Status')\n",
    "plt.ylabel('Gemiddelde IMDb-score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse van regisseurs: Kijk naar het aantal Oscars gewonnen per regisseur\n",
    "director_awards = merged_df[merged_df['winner'] == True].groupby('director_name').size().sort_values(ascending=False).head(40)\n",
    "\n",
    "# Maak een bar chart voor de top 10 regisseurs met de meeste Oscars gewonnen\n",
    "plt.figure(figsize=(12, 6))\n",
    "director_awards.plot(kind='bar', color='purple')\n",
    "plt.title('Top 10 Regisseurs met de Meeste Oscars Gewonnen')\n",
    "plt.xlabel('Regisseur')\n",
    "plt.ylabel('Aantal Oscars Gewonnen')\n",
    "plt.xticks(rotation=25, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De regrisseur speelt zeker een rol in het behalen van een oscar. Van de gene die winnen hebben vele rond de 10 oscars gewonnen en we hebben er een paar, zoals Steven spielberg die ver boven het gemiddelde zitten. Wellicht een goede manier om een baseline model van te maken. \n",
    "\n",
    "### Correlatie bekijken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse van correlaties\n",
    "merged_df['oscar_won_numeric'] = merged_df['winner'].apply(lambda x: 1 if x == True else (0 if x == False else None))\n",
    "\n",
    "# Selecteer de feature variables\n",
    "feat_columns = ['budget', 'imdb_score', 'duration', 'num_critic_for_reviews', \n",
    "                   'num_user_for_reviews', 'movie_facebook_likes', 'actor_1_facebook_likes']\n",
    "\n",
    "# Voeg de 'Oscar gewonnen' kolom toe aan de selectie\n",
    "correlation_data = merged_df[feat_columns + ['oscar_won_numeric']]\n",
    "\n",
    "# Bereken de correlatiematrix\n",
    "correlation_matrix = correlation_data.corr()\n",
    "\n",
    "# Plot de correlatiematrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlatiematrix van numerieke variabelen')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relatief slechte correlaties laten we doorgaan naar het voorspellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpele baseline: voorspellen dat geen enkele film een Oscar wint\n",
    "cleaned_df = merged_df.dropna(subset=['director_name', 'oscar_won_numeric'])\n",
    "y_test = cleaned_df['oscar_won_numeric'].sample(frac=0.2, random_state=42)\n",
    "y_baseline_pred = [0] * len(y_test)\n",
    "baseline_accuracy = accuracy_score(y_test, y_baseline_pred) * 100\n",
    "\n",
    "print(f\"Baseline Accuracy: {baseline_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecteer de features voor het model\n",
    "feature_columns = ['budget', 'imdb_score', 'duration', 'num_critic_for_reviews', \n",
    "                   'num_user_for_reviews', 'movie_facebook_likes', 'actor_1_facebook_likes']\n",
    "\n",
    "X_full = cleaned_df[feature_columns].fillna(0)\n",
    "y_full = cleaned_df['oscar_won_numeric']\n",
    "\n",
    "# Split de dataset in training en test sets\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X_full, y_full, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_full, y_train_full)\n",
    "rf_predictions = rf_model.predict(X_test_full)\n",
    "rf_accuracy = accuracy_score(y_test_full, rf_predictions)\n",
    "rf_classification_report = classification_report(y_test_full, rf_predictions)\n",
    "\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.2f}\")\n",
    "print(\"Random Forest Classification Report:\\n\", rf_classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Support Vector Classifier (SVC)\n",
    "svc_model = SVC(probability=True, random_state=42)\n",
    "svc_model.fit(X_train_full, y_train_full)\n",
    "svc_predictions = svc_model.predict(X_test_full)\n",
    "svc_accuracy = accuracy_score(y_test_full, svc_predictions)\n",
    "svc_classification_report = classification_report(y_test_full, svc_predictions)\n",
    "\n",
    "print(f\"SVC Accuracy: {svc_accuracy:.2f}\")\n",
    "print(\"SVC Classification Report:\\n\", svc_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusie onderzoeksvraag 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De data is dus niet goed gemerged en zal verder onderzocht moeten worden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onderzoeksvraag 3: Hoe kunnen budget en omzet worden gebruikt om logische clusters van de films te vinden?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = pd.read_csv('data/movie-1.csv')\n",
    "\n",
    "# Toon de maximale informatie die de dataframe kan geven.\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Formatteer alle grote getallen voor een betere leesbaarheid.\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfr.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om clusters te bepalen in een dataset gaan we nu gebruik maken van unsupervised learning. De algoritmes die we gaan toepassen zijn KMeans en GMM.\n",
    "\n",
    "We maken een nieuw dataframe aan met 'gross' en 'budget'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gross_budget = dfr[['gross', 'budget']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bekijken hoeveel NaN values in de dataset voorkomen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gross_budget.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bekijken hoeveel rows het volledige df bevat. Als de NaN waardes maar een klein percentage van de volledige dataset bevat kunnen deze worden verwijderd. Als het een groot percentage bevat dan moeten we kijken of we dit logisch in kunnen vullen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = len(df_gross_budget)\n",
    "print(f'aantal rows in de totale datasframe: {total_rows}')\n",
    "nan_rows = df_gross_budget.isna().any(axis=1).sum()\n",
    "print(f'aantal nan rows in de totale datasframe: {nan_rows}')\n",
    "nan_percentage_rows = ((nan_rows / total_rows) * 100).round(1)\n",
    "print(f'Bevat NaN rows t.o.v. totale dataframe: {nan_percentage_rows}%')\n",
    "\n",
    "# Plotten\n",
    "labels = ['Rijen met NaN', 'Rijen zonder NaN']\n",
    "values = [nan_rows, total_rows - nan_rows]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(values, labels=labels, autopct='%1.1f%%', startangle=90, colors=['lightcoral', 'lightgreen'], explode=[0.1, 0])\n",
    "plt.title('Verdeling van rijen met en zonder NaN-waarden', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit is een aanzienlijk groot percentage NaN's. We gaan de data opvullen. Maar eerst moeten we bekijken welke kolommen uit de dataset het meest correleren. De kolommen die het meest correleren met gross en budget kunnen worden gebruikt om de missende data in te vullen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecteer numerieke kolommen voor correlatie analyse\n",
    "numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "correlation_matrix = df[numeric_columns].corr()\n",
    "\n",
    "# Plot correlatie heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, \n",
    "            annot=True,\n",
    "            cmap='coolwarm',\n",
    "            center=0,\n",
    "            fmt='.2f')\n",
    "plt.title('Correlatie tussen numerieke variabelen')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print de top 5 correlaties met budget en gross\n",
    "print(\"\\nTop 5 correlaties met budget:\")\n",
    "budget_correlations = correlation_matrix['budget'].sort_values(ascending=False)\n",
    "print(budget_correlations.head())\n",
    "\n",
    "print(\"\\nTop 5 correlaties met gross:\")\n",
    "gross_correlations = correlation_matrix['gross'].sort_values(ascending=False)\n",
    "print(gross_correlations.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De enige matige correlaties zijn tussen de gross en num_voted_users en num_users_for_reviews. We zullen deze 2 kolommen gebruiken om de missende NaN values in te vullen van gross. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vul missende waarden van 'gross' in op basis van gemiddelden per cluster\n",
    "# Cluster bepalen op basis van 'num_voted_users' en 'num_user_for_reviews'\n",
    "\n",
    "# Maak een nieuwe kolom voor clustering (bijvoorbeeld afronden van aantallen gebruikers)\n",
    "df['cluster'] = (\n",
    "    df['num_voted_users'].fillna(0).round(-3).astype(int).astype(str) + '_' +\n",
    "    df['num_user_for_reviews'].fillna(0).round(-2).astype(int).astype(str)\n",
    ")\n",
    "\n",
    "# Bereken gemiddelde 'gross' per cluster\n",
    "cluster_gross_mean = df.groupby('cluster')['gross'].mean()\n",
    "\n",
    "# Vul NaN-waarden van 'gross' in met de gemiddelden per cluster\n",
    "df['gross'] = df.apply(\n",
    "    lambda row: cluster_gross_mean[row['cluster']] if pd.isna(row['gross']) else row['gross'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Verwijder tijdelijke clusterkolom\n",
    "df.drop(columns=['cluster'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weer opnieuw een dataframe maken met alleen gross en budget maar dan met de ingevulde gross kolom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['gross', 'budget']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weer alle NaN values checken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opnieuw bekijken hoeveel procent NaN waarden bevat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = len(df)\n",
    "print(f'aantal rows in de totale datasframe: {total_rows}')\n",
    "nan_rows = df.isna().any(axis=1).sum()\n",
    "print(f'aantal nan rows in de totale datasframe: {nan_rows}')\n",
    "nan_percentage_rows = ((nan_rows / total_rows) * 100).round(1)\n",
    "print(f'Bevat NaN rows t.o.v. totale dataframe: {nan_percentage_rows}%')\n",
    "\n",
    "# Plotten\n",
    "labels = ['Rijen met NaN', 'Rijen zonder NaN']\n",
    "values = [nan_rows, total_rows - nan_rows]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(values, labels=labels, autopct='%1.1f%%', startangle=90, colors=['lightcoral', 'lightgreen'], explode=[0.1, 0])\n",
    "plt.title('Verdeling van rijen met en zonder NaN-waarden', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hebben het aantal NaN values verlaagd van 22.8% tot 10.1%. Dit is nogsteeds relatief veel maar helaas is er weinig correlatie met de budget kolom waardoor we deze niet verder in kunnen vullen. Daarom kiezen we ervoor om de resterende NaN waarden te verwijderen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle NaN's verwijderen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opnieuw bekijken hoeveel NaN's in de dataset voorkomen. Na het verwijderen ervan moeten ze voor allebei op 0 staan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het dataframe bekijken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verwijderen van outliers ##\n",
    "\n",
    "Omdat de modellen gevoelig zijn voor outliers gaan we identificeren welke we gaan verwijderen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.boxplot_gross_and_budget(df, 'gross')\n",
    "fn.histogram_gross(df, 'gross')\n",
    "\n",
    "fn.boxplot_gross_and_budget(df, 'budget')\n",
    "fn.histogram_gross(df, 'budget')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als we kijken naar een combinatie van de boxplots en histogrammen, dan zien we dat er extreme outliers in onze dataset voorkomen. Onze onderzoeksvraag vraagt niet om bijzondere gevallen te bepalen, maar om logische clusters te bepalen, wat na verwijderen van de outliers nogsteeds kan worden gedaan. Hierdoor besluiten we alle outliers te verwijderen uit onze dataset. Hierbij maken we gebruik van de functies uit functies.py. Ook bekijken we het aantal rijen en kolommen voordat we ze gaan verwijderen om te checken of ze echt zijn verwijderd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fn.remove_outliers(df, 'gross')\n",
    "df = fn.remove_outliers(df, 'budget')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checken of de outliers zijn verwijderd door het aantal rijen en kolommen te bekijken. Dit is inderdaad een lager getal dan eerst, wat betekend dat ze zijn verwijderd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ook bekijken we de histogrammen opnieuw. De x as moet een bereik hebben wat overeenkomt met wat we op de boxplots zagen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.histogram_gross(df, 'gross')\n",
    "fn.histogram_gross(df, 'budget')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het bereik op de x as komt inderdaad overeen met wat we zagen in de boxplots voordat we de outliers hebben verwijderd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu gaan we kijken of er na opvulling en opschoning van onze dataset logische clusters kunnen worden bepaald met unsupervised learning. De 2 modellen die we gebruiken zijn kmeans en gmm. We gebruiken deze 2 modellen omdat ze relatief eenvoudig, efficiënt en effectief zijn bij het vinden van clusters in onze continueu data. Kmeans kan goed voor bolvormige clusters modelleren en gmm kan goed verschillende vormen moddeleren doordat het flexibeler is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code afkomstig van les CM10\n",
    "# kMeans en GMM maken gebruik van afstandsmaten, daarom is standaardiseren belangrijk\n",
    "df.reset_index(inplace = True)\n",
    "\n",
    "# We passen scaling toe zodat de afstandmaten beter zijn verdeeld onder elkaar.\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df[['gross', 'budget']])\n",
    "df_z = pd.DataFrame(scaler.transform(df[['gross', 'budget']]), columns=['gross_z', 'budget_z'])\n",
    "df[['gross_z', 'budget_z']] = df_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kijken of de correcte kolommen zijn aangemaakt. gross_z en budget_z zijn inderdaad aangemaakt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moddeleren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gaan als eerst KMeans toepassen op onze dataset en bekijken welke clusters dit moddeleert. We kiezen hier handmatig 5 clusters. Dit doen we omdat onze hoofdvraag vraagt om 5 clusters: blockbuster films, flop films, cult films, mid range films en rest van de films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maken van een willekeurige clustering\n",
    "model_kMeans = KMeans(n_clusters=5, random_state=0)\n",
    "X_kMeans = df[['gross_z', 'budget_z']]\n",
    "\n",
    "# Clusters 'voorspellen' en opslaan\n",
    "prediction_kMeans = model_kMeans.fit_predict(X_kMeans)\n",
    "df['cluster_number'] = model_kMeans.predict(X_kMeans)\n",
    "\n",
    "# Plotten van 'omzet' en 'budget' en als kleur de clusters\n",
    "plt.scatter(df['gross'], df['budget'], c=df['cluster_number'], cmap='plasma')\n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(fn.euro_formatter))\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(fn.euro_formatter))\n",
    "plt.title('Scatterplot: omzet vs budget')\n",
    "plt.xlabel('omzet')\n",
    "plt.ylabel('budget')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als we naar de plot kijken zien we dat KMeans uitstekende logische clusters kan vormen. Alle kleuren staan gegroupeerd bij elkaar met logische parameters per groep. Helaas geeft dit geen clusters die overeenkomen met de 5 soorten films uit onze hoofdvraag. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om nog even bij KMeans te blijven gaan we hier de 'elbow method' toepassen. Dit doen we omdat dit het punt is waar het toevoegen van extra clusters nauwelijks meer leidt tot een significante verbetering in de clusteringkwaliteit. Als de 'knik' valt op 5 weten we dat dit het optimale punt is om te zoeken naar clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code afkomstig van les CM10\n",
    "\n",
    "data = []\n",
    "\n",
    "max_k = 20\n",
    "\n",
    "for i in range(1, max_k):\n",
    "    model_kMeans = KMeans(n_clusters=i, random_state=0)\n",
    "    X_kMeans = df[['gross_z', 'budget_z']]\n",
    "\n",
    "    # Clusters 'voorspellen' en opslaan\n",
    "    model_kMeans.fit(X_kMeans)\n",
    "\n",
    "    data.append([i, model_kMeans.score(X_kMeans)])\n",
    "\n",
    "df_plot_kmeans = pd.DataFrame(data, columns=['k', 'Score'])\n",
    "\n",
    "fig = plt.figure(figsize=(5,5), dpi=150)\n",
    "\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.set(xlim=(0,max_k),\n",
    "       xlabel='n',\n",
    "       ylabel='Score',\n",
    "       title='Kmeans: score vs k')\n",
    "\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(max_k))\n",
    "ax.ticklabel_format(useOffset=False)\n",
    "ax.plot(df_plot_kmeans['k'], df_plot_kmeans['Score'], '-o')\n",
    "\n",
    "ax.legend(['k'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als we kijken naar de plot van de 'elbow method' zien we dat de 'knik' zit bij n=2. Dit punt geeft de optimale balans in modelcomplexiteit en clusteringkwaliteit. De knik valt dus niet op 5, wat betekend dat we eerder met n=5 hebben overclusterd. Dit betekent niet dat het geen logische clusters heeft gevonden, maar wel dat het overcomplexe clusters probeert te vinden zonder dat de kwaliteit van de clusters omhoog gaat. Hieronder plotten we de optimale balans met n=2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maken van een willekeurige clustering\n",
    "model_kMeans = KMeans(n_clusters=2, random_state=0)\n",
    "X_kMeans = df[['gross_z', 'budget_z']]\n",
    "\n",
    "# Clusters 'voorspellen' en opslaan\n",
    "prediction_kMeans = model_kMeans.fit_predict(X_kMeans)\n",
    "df['cluster_number'] = model_kMeans.predict(X_kMeans)\n",
    "\n",
    "# Plotten van 'omzet' en 'budget' en als kleur de clusters\n",
    "plt.scatter(df['gross'], df['budget'], c=df['cluster_number'], cmap='plasma')\n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(fn.euro_formatter))\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(fn.euro_formatter))\n",
    "plt.title('Scatterplot: omzet vs budget')\n",
    "plt.xlabel('omzet')\n",
    "plt.ylabel('budget')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ook dit geeft weer logische clusters zoals laag budget en omzet en hoog budget en omzet, maar geen clusters die slaan op onze hoofdvraag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu gaan we hetzelfde doen maar dan met GMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maken van een willekeurige clustering\n",
    "model_gmm = gmm(n_components=5, random_state=0)\n",
    "X_gmm = df[['gross_z', 'budget_z']]\n",
    "\n",
    "# Clusters 'voorspellen' en opslaan\n",
    "prediction_gmm = model_gmm.fit_predict(X_gmm)\n",
    "df['cluster_number'] = model_gmm.predict(X_gmm)\n",
    "\n",
    "# Plotten van 'omzet' en 'budget' en als kleur de clusters\n",
    "plt.scatter(df['gross'], df['budget'], c=df['cluster_number'], cmap='plasma')\n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(fn.euro_formatter))\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(fn.euro_formatter))\n",
    "plt.title('Scatterplot: omzet vs budget')\n",
    "plt.xlabel('omzet')\n",
    "plt.ylabel('budget')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ook hier zie je dat het clusters maakt die logisch zijn maar weer niet slaan op onze hoofdvraag. De vormen zijn wat flexibeler en rondvormig, wat een kenmerk is van gmm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dan gaan we kijken naar de elbow method voor gmm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code afkomstig van les CM10\n",
    "data = []\n",
    "\n",
    "max_n = 20\n",
    "\n",
    "for i in range(1, max_k):\n",
    "    model_gmm = gmm(n_components=i, random_state=0)\n",
    "    X_gmm = df[['gross_z', 'budget_z']]\n",
    "\n",
    "    prediction_gmm = model_gmm.fit(X_gmm)\n",
    "    data.append([i, model_gmm.score(X_gmm)])\n",
    "\n",
    "df_plot_gmm = pd.DataFrame(data, columns=['n', 'Score'])\n",
    "\n",
    "fig = plt.figure(figsize=(5,5), dpi=150)\n",
    "\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.set(xlim=(0,max_n),\n",
    "       xlabel='n',\n",
    "       ylabel='Score',\n",
    "       title='GMM: score vs n')\n",
    "\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(20))\n",
    "ax.ticklabel_format(useOffset=False)\n",
    "ax.plot(df_plot_gmm['n'], df_plot_gmm['Score'], '-o')\n",
    "\n",
    "ax.legend(['n'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De knik bij de elbow method voor gmm zit op 4. Dit punt geeft de optimale balans in modelcomplexiteit en clusteringkwaliteit. De knik valt dus niet op 5, wat betekend dat we eerder met n=5 hebben overclusterd. Dit betekent niet dat het geen logische clusters heeft gevonden, maar wel dat het overcomplexe clusters probeert te vinden zonder dat de kwaliteit van de clusters omhoog gaat. Zeker bij deze want hier flatlined de plot tussen 4 en 5. Hieronder plotten we de optimale balans met n=4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maken van een willekeurige clustering\n",
    "model_gmm = gmm(n_components=4, random_state=0)\n",
    "X_gmm = df[['gross_z', 'budget_z']]\n",
    "\n",
    "# Clusters 'voorspellen' en opslaan\n",
    "prediction_gmm = model_gmm.fit_predict(X_gmm)\n",
    "df['cluster_number'] = model_gmm.predict(X_gmm)\n",
    "\n",
    "# Plotten van 'omzet' en 'budget' en als kleur de clusters\n",
    "plt.scatter(df['gross'], df['budget'], c=df['cluster_number'], cmap='plasma')\n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(fn.euro_formatter))\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(fn.euro_formatter))\n",
    "plt.title('Scatterplot: omzet vs budget')\n",
    "plt.xlabel('omzet')\n",
    "plt.ylabel('budget')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ook hier zie je dat het clusters maakt die logisch zijn maar weer niet slaan op onze hoofdvraag. De logische clusters hebben allemaal dezelfde combinatie van hoeveelheid in budget en omzet. De vormen zijn wat flexibeler en rondvormig, wat een kenmerk is van gmm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natuurlijk zouden we dit zelf wel kunnen maken op basis van een paar regels, namelijk:\n",
    "\n",
    "Het opdelen van de films in 5 categorieën.\n",
    "\n",
    "1. Blockbuster: hoog budget met hoge omzet\n",
    "2. Flop: hoog budget met lage omzet\n",
    "3. Cultfilm: laag budget met hoge omzet\n",
    "4. Mid-Range Movie: Gemiddeld budget met gemiddelde omzet\n",
    "5. Average: Alle andere gevallen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In volledige dataFrame, alle NaN waarde verwijderen van budget en gross.\n",
    "df = dfr[['budget', 'gross']].dropna()\n",
    "\n",
    "# Extreme waarde van budget en gross worden ook verwijderd.\n",
    "df = df[(df['budget'] < 350000000) & (df['gross'] < 1000000000)] \\\n",
    "\n",
    "# Zie functies.py voor de functie classify_movie\n",
    "df['Category'] = df.apply(fn.classify_movie, axis=1)\n",
    "\n",
    "# Scatterplot Visualiseren met kleur\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = {'Blockbuster':'green', 'Flop':'red', 'Cultfilm':'blue', 'Average':'orange', 'Mid-Range Movie':'purple'}\n",
    "scatter = plt.scatter(df['budget'], df['gross'], \n",
    "                      c=df['Category'].map(colors), alpha=0.5, s=60, edgecolor='k', marker='o')\n",
    "\n",
    "# Titel en labels\n",
    "plt.title('Filmclusters Gebaseerd op gudget en winst', fontsize=16)\n",
    "plt.xlabel('Budget (in dollars)', fontsize=14)\n",
    "plt.ylabel('Omzet (in dollars)', fontsize=14)\n",
    "\n",
    "# Weergavegrenzen\n",
    "plt.xlim(0, 300000000)  \n",
    "plt.ylim(0, 800000000) \n",
    "\n",
    "# Grafiek lijn\n",
    "plt.grid(True, linestyle='-', alpha=0.5)\n",
    "\n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(fn.euro_formatter))\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(fn.euro_formatter))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kleur en kermerken van de clusters in de scatterplot**\n",
    "\n",
    "- **Groen: blockbuster films**\n",
    "\n",
    "Deze films zijn met een hoog budget (> 100 miljoen dollar) en met een hoge omzet (>300 miljoen dollar).\n",
    "\n",
    "We zien groene cluster rechterboven in de grafiek. De succesvolle films.\n",
    "\n",
    "\n",
    "- **Rood: flop films**\n",
    "\n",
    "Deze films zijn met een hoog budget (> 100 miljoen dollar) en met een lage omzet (<50 miljoen dollar).\n",
    "\n",
    "We zien rode cluster rechtsonder in de grafiek. Deze is een klein cluster.\n",
    "\n",
    "\n",
    "- **Blauw: cultfilms**\n",
    "\n",
    "Deze films zijn met een laag budget (<20 miljoen dollar) en met een relatief hoge omzet (>50 miljoen dollar).\n",
    "\n",
    "We zien blauwe cluster linkerboven in de grafiek. Dit cluster laten zien de films met een laag budget toch tot een groot succes kan zijn.\n",
    "\n",
    "\n",
    "- **Paars: mid range films**\n",
    "\n",
    "Deze films zijn met een middelgroot budget (50-100 miljoen dollar) en met een middelgroot omzet (50-300 miljoen dollar).\n",
    "\n",
    "We zien paarse cluster midden in de grafiek. Deze is een groot cluster, betekent er zijn heel veel prima films.\n",
    "\n",
    "\n",
    "- **Orange: rest van de films**\n",
    "\n",
    "Alle film die niet in bovenstaande categorieën.\n",
    "\n",
    "We zien orange cluster verspreid over de grafiek. Er zijn heel veel films die gewoon middelmatige resultaten halen, dus niet te ondersheiden in budget of omzet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusie onderzoeksvraag 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Door middel van unsupervised learning kunnen er logische clusters gemaakt worden. Alle 2 de modellen presteren hier goed in. De kleuren zijn niet verspreid van elkaar wat dit aanduidt. Er is echter geen goed onderscheid te maken tussen blockbusters, flops en cultfilms als je kijkt naar de kleuren van de clusters. Zelfs met verschillende k waarden van beide modellen wordt het er niet beter op.\n",
    "\n",
    "We kunnen wel door middel van rule based tabellen een logische cluster maken. Maar goed, dat is supervised en niet unsupervised learning.\n",
    "\n",
    "Het is dus mogelijk om logische clusters te vinden met onze unsupervised technieken, maar deze kunnen geen onderscheid vinden tussen de 5 verschillende films."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CM2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
