{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter \n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions are defined here to improve readability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(dataframe, columnName):\n",
    "    q1 = np.quantile(dataframe[columnName], 0.25)\n",
    " \n",
    "    q3 = np.quantile(dataframe[columnName], 0.75)\n",
    "    \n",
    "    iqr = q3-q1\n",
    "    \n",
    "    upper_bound = q3+(1.5*iqr)\n",
    "    lower_bound = q1-(1.5*iqr)\n",
    "\n",
    "    return dataframe[(dataframe[columnName] >= lower_bound) & (dataframe[columnName] <= upper_bound)]\n",
    "\n",
    "def boxplot_gross(dataframe, columnName):\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.boxplot(dataframe[columnName])\n",
    "    def euro_formatter(x, _):\n",
    "        if x >= 1000000:\n",
    "            return f\"${x / 1000000:.0f}M\"\n",
    "    plt.gca().yaxis.set_major_formatter(FuncFormatter(euro_formatter))\n",
    "    ax1.set_title(f\"Boxplot from {columnName}\")\n",
    "    ax1.set_xlabel(columnName)\n",
    "    ax1.set_ylabel('Gross')\n",
    "    plt.show()\n",
    "\n",
    "def histogram_gross(dataframe, columnName):\n",
    "    plt.hist(dataframe[columnName], bins=100, color='skyblue', edgecolor='black')\n",
    "    def euro_formatter(x, _):\n",
    "        if x >= 1000000:\n",
    "            return f\"${x / 1000000:.0f}M\"\n",
    "    plt.gca().xaxis.set_major_formatter(FuncFormatter(euro_formatter))\n",
    "    plt.title(f\"The frequency of {columnName}\")\n",
    "    plt.xlabel('Gross')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "def boxplot_likes(dataframe, columnName):\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.boxplot(dataframe[columnName])\n",
    "    ax1.set_title(f\"Boxplot from {columnName}\")\n",
    "    ax1.set_xlabel(columnName)\n",
    "    ax1.set_ylabel('Amount of likes')\n",
    "    plt.show()\n",
    "\n",
    "def histogram_likes(dataframe, columnName):\n",
    "    plt.hist(dataframe[columnName], bins=100, color='skyblue', edgecolor='black')\n",
    "    plt.title(f\"Frequency of {columnName}\")\n",
    "    plt.xlabel('Likes')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "def correlation_plot(df, targetVariable, featureVariable):\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.scatter(df[targetVariable], df[featureVariable], s=3)\n",
    "\n",
    "    def euro_formatter(x, _):\n",
    "        if x >= 1000000:\n",
    "            return f\"${x / 1000000:.0f}M\"\n",
    "    plt.gca().xaxis.set_major_formatter(FuncFormatter(euro_formatter))\n",
    "    \n",
    "    ax1.set_xlabel(targetVariable)\n",
    "    ax1.set_ylabel(featureVariable)\n",
    "\n",
    "    correlation = df[[targetVariable, featureVariable]].corr().iloc[0, 1]\n",
    "\n",
    "    ax1.set_title(f\"{targetVariable} vs {featureVariable} (r = {correlation:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = pd.read_csv('data/movie-1.csv')\n",
    "\n",
    "# Show the maximum info the dataframe can give.\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Format all big numbers for better readability.\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Copy of the dataset**\n",
    "\n",
    "Making a copy of the data to work with so we will not alter the actual dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfr.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Taking a look at the data we're given.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the column names to see with what kind of variables we're working with**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(f\"column: {col}, dtype: {df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Measurement levels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename=\"meet.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Target and Feature variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureVariables = ['director_name', 'director_facebook_likes',\n",
    "                    'actor_1_name', 'actor_1_facebook_likes', \n",
    "                    'actor_2_name', 'actor_2_facebook_likes', \n",
    "                    'actor_3_name', 'actor_3_facebook_likes', \n",
    "                    'cast_total_facebook_likes',\n",
    "                    'movie_facebook_likes',\n",
    "                    'imdb_score']\n",
    "\n",
    "targetVariable = ['gross']\n",
    "\n",
    "numVariable =   ['director_facebook_likes', \n",
    "                'actor_1_facebook_likes', \n",
    "                'actor_2_facebook_likes', \n",
    "                'actor_3_facebook_likes', \n",
    "                'cast_total_facebook_likes', \n",
    "                'movie_facebook_likes', \n",
    "                'imdb_score',\n",
    "                'gross']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make another DF with only the columns we're interested in.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape) #check impact\n",
    "df = df[featureVariables + targetVariable]\n",
    "print(df.shape) #check impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check NaN values**\n",
    "\n",
    "Drop all the NaN values in all the feature and target variables. (for now) Later on we will do more research on how to properly handle these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop all NaN values. We can not replace them because the vast majority contains our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape) #check impact\n",
    "df = df.dropna()\n",
    "print(df.shape) #check impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we will analyse all columns to check for anomalies.**\n",
    "\n",
    "All the statistics look clean. \n",
    "\n",
    "All columns containing 'names' have NaN and number where this is expected. \n",
    "\n",
    "All columns containing 'likes' have NaN and a number where this is expected. Also no weird min or max values\n",
    "\n",
    "The column 'imdb_score' has values only between 0 and 10 which is expected.\n",
    "\n",
    "And lastly the column 'gross' has a natural order of magnitude from min to max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not delete any of the outliers from our target variable 'gross'. However, for our feature variables there are some weird outliers and a lot of directors and actors getting 0 likes on facebook. We will need to dive deeper and see if we can fill those 0 values with something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Count before removing outliers: {df.shape}\")\n",
    "boxplot_gross(df, 'gross')\n",
    "histogram_gross(df, 'gross')\n",
    "# df = remove_outliers(df, 'gross')\n",
    "# print(f\"Count after removing outliers: {df.shape}\")\n",
    "# boxplot_gross(df, 'gross')\n",
    "# histogram_gross(df, 'gross')\n",
    "\n",
    "for feature in featureVariables:\n",
    "    if 'like' in feature:\n",
    "        # print(f\"Count before removing outliers: {df.shape}\")\n",
    "        boxplot_likes(df, feature)\n",
    "        histogram_likes(df, feature)\n",
    "        # df = remove_outliers(df, feature)\n",
    "        # print(f\"Count after removing outliers: {df.shape}\")\n",
    "        # boxplot_likes(df, feature)\n",
    "        # histogram_likes(df, feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate the numeric variables against the target variable so we can look which features are (somewhat) important to the target variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = df[numVariable].corr()['gross'].sort_values(ascending=False)\n",
    "\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_plot(df, 'gross', 'director_facebook_likes')\n",
    "correlation_plot(df, 'gross', 'actor_1_facebook_likes')\n",
    "correlation_plot(df, 'gross', 'actor_2_facebook_likes')\n",
    "correlation_plot(df, 'gross', 'actor_3_facebook_likes')\n",
    "correlation_plot(df, 'gross', 'cast_total_facebook_likes')\n",
    "correlation_plot(df, 'gross', 'movie_facebook_likes')\n",
    "correlation_plot(df, 'gross', 'imdb_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scatterplots**\n",
    "\n",
    "Here we will plot some scatterplots to get a better insight in our feature variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter(variable, x_label):\n",
    "    plt.scatter(df[variable], df['imdb_score'])\n",
    "    plt.title(f'IMDb Score vs. {x_label}')\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel('IMDb Score')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter('movie_facebook_likes', 'Movie Facebook Likes')\n",
    "scatter('gross', 'Gross Revenue')\n",
    "scatter('cast_total_facebook_likes', 'Total Cast Facebook Likes')\n",
    "scatter('actor_1_facebook_likes', 'Actor 1 Facebook Likes')\n",
    "scatter('actor_2_facebook_likes', 'Actor 2 Facebook Likes')\n",
    "scatter('actor_3_facebook_likes', 'Actor 3 Facebook Likes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assign dummy values to all the names. This is needed to calculate our model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select numeric feature variables\n",
    "X_numeric = df[['director_facebook_likes', \n",
    "                'actor_1_facebook_likes', \n",
    "                'actor_2_facebook_likes', \n",
    "                'actor_3_facebook_likes', \n",
    "                'cast_total_facebook_likes', 'movie_facebook_likes', 'imdb_score',\n",
    "                'gross' # Comment this one out when applying a model\n",
    "                ]]\n",
    "\n",
    "#We assign all other column values to dummy values \n",
    "X_dummies = pd.get_dummies(df[['director_name', 'actor_1_name', 'actor_2_name', 'actor_3_name']], dtype = int)\n",
    "\n",
    "#Assign the 2 dataframes to 1 dataframe again\n",
    "X = pd.concat([X_numeric, X_dummies], axis = 1)\n",
    "y = df[['gross']]\n",
    "\n",
    "df = X\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape) #check impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will now look for all the likes statistics per director and actor**\n",
    "\n",
    "As you can see, there are a lot of directors and actors with major movies (high gross) that get zero likes on their facebook. Especially with directors. We will need to fill those in. This will be done by assigning the mean likes value of similar movies grouped by their 'gross'. A visual representation with actual implementation will follow next week. \n",
    "\n",
    "When this is done we think our correlation plots will have a straighter line, which indicates a better corrolation and will most likely improve our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likeList = []\n",
    "grossList = []\n",
    "\n",
    "for column in df.columns:\n",
    "    if 'director_name' in column:\n",
    "\n",
    "        rowsWithDirector = df[df[column] == 1]\n",
    "\n",
    "        infoLikes = rowsWithDirector[['director_facebook_likes']]\n",
    "        infoGross = rowsWithDirector[['gross']]\n",
    "\n",
    "        describeLikeStats = infoLikes.describe(include='all').transpose()\n",
    "        describeGrossStats = infoGross.describe(include='all').transpose()\n",
    "\n",
    "        describeLikeStats = describeLikeStats.add_prefix('likes_')\n",
    "        describeGrossStats = describeGrossStats.add_prefix('gross_')\n",
    "\n",
    "        describeLikeStats['director'] = column\n",
    "        describeGrossStats['director'] = column\n",
    "\n",
    "        likeList.append(describeLikeStats)\n",
    "        grossList.append(describeGrossStats)\n",
    "\n",
    "directorLikeStats = pd.concat(likeList).reset_index(drop=True)\n",
    "directorGrossStats = pd.concat(grossList).reset_index(drop=True)\n",
    "\n",
    "directorStats = pd.merge(directorLikeStats, directorGrossStats, on='director', how='outer')\n",
    "\n",
    "directorStats = directorStats.sort_values(by='likes_mean', ascending=True)\n",
    "\n",
    "directorStats.head(10)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likeActor1List = []\n",
    "grossActor1List = []\n",
    "\n",
    "for column in df.columns:\n",
    "    if 'actor_1' in column:\n",
    "\n",
    "        rowsWithActor1 = df[df[column] == 1]\n",
    "\n",
    "        infoLikes = rowsWithActor1[['actor_1_facebook_likes']]\n",
    "        infoGross = rowsWithActor1[['gross']]\n",
    "\n",
    "        describeLikeStats = infoLikes.describe(include='all').transpose()\n",
    "        describeGrossStats = infoGross.describe(include='all').transpose()\n",
    "\n",
    "        describeLikeStats = describeLikeStats.add_prefix('likes_')\n",
    "        describeGrossStats = describeGrossStats.add_prefix('gross_')\n",
    "\n",
    "        describeLikeStats['actor1'] = column\n",
    "        describeGrossStats['actor1'] = column\n",
    "        \n",
    "        likeActor1List.append(describeLikeStats)\n",
    "        grossActor1List.append(describeGrossStats)\n",
    "\n",
    "actor1LikeStats = pd.concat(likeActor1List).reset_index(drop=True)\n",
    "actor1GrossStats = pd.concat(grossActor1List).reset_index(drop=True)\n",
    "\n",
    "actor1Stats = pd.merge(actor1LikeStats, actor1GrossStats, on='actor1', how='outer')\n",
    "\n",
    "actor1Stats = actor1Stats.sort_values(by='likes_mean', ascending=True)\n",
    "\n",
    "actor1Stats.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likeActor2List = []\n",
    "grossActor2List = []\n",
    "\n",
    "for column in df.columns:\n",
    "    if 'actor_2' in column:\n",
    "\n",
    "        rowsWithActor2 = df[df[column] == 1]\n",
    "\n",
    "        infoLikes = rowsWithActor2[['actor_2_facebook_likes']]\n",
    "        infoGross = rowsWithActor2[['gross']]\n",
    "\n",
    "        describeLikeStats = infoLikes.describe(include='all').transpose()\n",
    "        describeGrossStats = infoGross.describe(include='all').transpose()\n",
    "\n",
    "        describeLikeStats = describeLikeStats.add_prefix('likes_')\n",
    "        describeGrossStats = describeGrossStats.add_prefix('gross_')\n",
    "\n",
    "        describeLikeStats['actor2'] = column\n",
    "        describeGrossStats['actor2'] = column\n",
    "        \n",
    "        likeActor2List.append(describeLikeStats)\n",
    "        grossActor2List.append(describeGrossStats)\n",
    "\n",
    "actor2LikeStats = pd.concat(likeActor2List).reset_index(drop=True)\n",
    "actor2GrossStats = pd.concat(grossActor2List).reset_index(drop=True)\n",
    "\n",
    "actor2Stats = pd.merge(actor2LikeStats, actor2GrossStats, on='actor2', how='outer')\n",
    "\n",
    "actor2Stats = actor2Stats.sort_values(by='likes_mean', ascending=True)\n",
    "\n",
    "actor2Stats.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likeActor3List = []\n",
    "grossActor3List = []\n",
    "\n",
    "for column in df.columns:\n",
    "    if 'actor_3' in column:\n",
    "        rowsWithActor3 = df[df[column] == 1]\n",
    "\n",
    "        infoLikes = rowsWithActor3[['actor_3_facebook_likes']]\n",
    "        infoGross = rowsWithActor3[['gross']]\n",
    "\n",
    "        describeLikeStats = infoLikes.describe(include='all').transpose()\n",
    "        describeGrossStats = infoGross.describe(include='all').transpose()\n",
    "\n",
    "        describeLikeStats = describeLikeStats.add_prefix('likes_')\n",
    "        describeGrossStats = describeGrossStats.add_prefix('gross_')\n",
    "\n",
    "        describeLikeStats['actor3'] = column\n",
    "        describeGrossStats['actor3'] = column\n",
    "        \n",
    "        likeActor3List.append(describeLikeStats)\n",
    "        grossActor3List.append(describeGrossStats)\n",
    "\n",
    "actor3LikeStats = pd.concat(likeActor3List).reset_index(drop=True)\n",
    "actor3GrossStats = pd.concat(grossActor3List).reset_index(drop=True)\n",
    "\n",
    "actor3Stats = pd.merge(actor3LikeStats, actor3GrossStats, on='actor3', how='outer')\n",
    "\n",
    "actor3Stats = actor3Stats.sort_values(by='likes_mean', ascending=True)\n",
    "\n",
    "actor3Stats.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
